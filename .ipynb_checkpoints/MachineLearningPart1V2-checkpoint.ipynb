{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "GXnMFrQ-NT5A",
    "outputId": "e473da43-8da2-4cdc-ffdf-1eb185f276b8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion \n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold, RandomizedSearchCV \n",
    "from sklearn.linear_model import Perceptron, LogisticRegressionCV, RidgeClassifierCV, SGDClassifier, PassiveAggressiveClassifier, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score,mean_absolute_error, confusion_matrix, silhouette_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc, classification_report,precision_score,recall_score,log_loss,f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, LabelEncoder, OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.preprocessing import MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer,minmax_scale,PolynomialFeatures\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn import tree\n",
    "import pandas_bokeh\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy import mean, std\n",
    "import pandas.testing as tm\n",
    "from pandas import ExcelWriter\n",
    "from scipy import stats\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer, SimpleImputer, KNNImputer\n",
    "\n",
    "from yellowbrick.features import PCA as PCA_YB\n",
    "from yellowbrick.features.radviz import RadViz\n",
    "from yellowbrick.features import pca_decomposition\n",
    "from yellowbrick.features import Manifold\n",
    "from yellowbrick.features import JointPlotVisualizer\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from yellowbrick.model_selection import CVScores\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.features import ParallelCoordinates\n",
    "from yellowbrick.model_selection import RFECV\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "#other\n",
    "from math import sqrt\n",
    "import inspect\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from scipy.stats import loguniform, uniform\n",
    "from bokeh import io\n",
    "\n",
    "import eli5\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5ckMkNrcNVg0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Basic', 'Graduation', 'Master', '2n Cycle', 'PhD'], dtype=object)]\n",
      "0    1906\n",
      "1     334\n",
      "Name: Response, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://gist.githubusercontent.com/YHYeoh/ad1a7f7170c72d621d05a70637540152/raw/5a6059c199e2c46d2f3d258f03d93cfea98e2749/marketing_campaign.csv\"\n",
    "data = pd.read_csv(DATASET_URL, sep = ';')\n",
    "\n",
    "pd.set_option('plotting.backend','pandas_bokeh')\n",
    "\n",
    "data.fillna(method = \"ffill\", inplace = True)\n",
    "data.isnull().values.any()\n",
    "\n",
    "\n",
    "education_order = [['Basic', 'Graduation', 'Master', '2n Cycle', 'PhD']]\n",
    "ordinal_encoder = OrdinalEncoder(categories=education_order)\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "\n",
    "data[\"Education\"] = (ordinal_encoder.fit_transform(data[\"Education\"].values.reshape(-1, 1))).astype(int)\n",
    "print(ordinal_encoder.categories_)\n",
    "\n",
    "data_copy = data\n",
    "marital_status_ohe = pd.get_dummies(data[\"Marital_Status\"],prefix=\"Marital\")\n",
    "ohe_cols = marital_status_ohe.columns\n",
    "data = pd.concat([data, marital_status_ohe], axis=1)\n",
    "\n",
    "\n",
    "data['enroll_year'] = pd.DatetimeIndex(data.Dt_Customer).year\n",
    "data['enroll_month'] = pd.DatetimeIndex(data.Dt_Customer).month\n",
    "data['enroll_day'] = pd.DatetimeIndex(data.Dt_Customer).day\n",
    "\n",
    "data.drop([\"ID\", 'Dt_Customer',\"Z_CostContact\",\"Z_Revenue\",\"Marital_Status\"], axis=1, inplace=True)\n",
    "\n",
    "categorical = ['Marital_Status']\n",
    "numerical = ['Year_Birth', 'Education', 'Marital_Status', 'Income', 'Kidhome',\n",
    "       'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
    "       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "       'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3',\n",
    "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',\n",
    "       'Complain', 'enroll_year', 'enroll_month', 'enroll_day']\n",
    "numerical_no_bool = ['Education','Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth','enroll_day','enroll_month','enroll_year']\n",
    "\n",
    "y = data.Response\n",
    "print(y.value_counts())\n",
    "X = data.drop(['Response'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.3)\n",
    "X_train_cont = X_train.drop(['AcceptedCmp3',\n",
    "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Education','Complain','Year_Birth','Marital_Absurd', 'Marital_Alone', 'Marital_Divorced',\n",
    "       'Marital_Married', 'Marital_Single', 'Marital_Together',\n",
    "       'Marital_Widow', 'Marital_YOLO', 'enroll_year', 'enroll_month',\n",
    "       'enroll_day'],axis=1)\n",
    "X_test_cont = X_test.drop(['AcceptedCmp3',\n",
    "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Education','Complain','Year_Birth','Marital_Absurd', 'Marital_Alone', 'Marital_Divorced',\n",
    "       'Marital_Married', 'Marital_Single', 'Marital_Together',\n",
    "       'Marital_Widow', 'Marital_YOLO', 'enroll_year', 'enroll_month',\n",
    "       'enroll_day'],axis=1)\n",
    "X_cont_column = X_train_cont.columns\n",
    "pcaX_train = X_train_cont\n",
    "pcaX_test = X_test_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkPBcz5KNZi6"
   },
   "outputs": [],
   "source": [
    "def hasmethod(obj, name):\n",
    "\treturn inspect.ismethod(getattr(obj, name, None))\n",
    "\n",
    "def ROC_Curve_Plot(model,X_test,y_test,name):\n",
    "\tpredProb = model.predict_proba(X_test)\n",
    "\tpreds = predProb[:,1]\n",
    "\tfpr, tpr, threshold = roc_curve(y_test, preds,pos_label=1)\n",
    "\troc_auc = auc(fpr, tpr)\n",
    "\tplt.close()\n",
    "\tplt.title(name+' Receiver Operating Characteristic')\n",
    "\tplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "\tplt.legend(loc = 'lower right')\n",
    "\tplt.plot([0, 1], [0, 1],'r--')\n",
    "\tplt.ylabel('True Positive Rate')\n",
    "\tplt.xlabel('False Positive Rate')\n",
    "\tplt.show()\n",
    "\treturn fpr,tpr\n",
    "\n",
    "def setupPreprocessPipeline(scaler):\n",
    "\tss = Pipeline(steps=[('scaler',scaler)])\n",
    "\t#ohe = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "\tpreprocess = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('cont', ss, numerical_no_bool)\n",
    "                        #('cat', ohe, categorical),\n",
    "                        #('le', le, ordinal),\n",
    "                        ],remainder='passthrough')\n",
    "\treturn preprocess\n",
    "\n",
    "def feature_importance(classifier, feature_names, scaler_name):\n",
    "\tif (hasattr(classifier,'coef_')):\n",
    "\t\timportance = classifier.coef_[0]\n",
    "\telif (hasattr(classifier,'coefs_')):\n",
    "\t\timportance = classifier.coefs_\n",
    "\telif (hasattr(classifier,'feature_importances_')):\n",
    "\t\timportance = classifier.feature_importances_\n",
    "\telse:\n",
    "\t\tprint(\"Cannot extract feature importance, skipping\")\n",
    "\t\treturn\n",
    "\n",
    "\t#for i,v in enumerate(importance):\n",
    "\t#\tprint('Feature: %d, Score: %.5f' % (i,v))\n",
    "\tzipped = zip(feature_names, importance)\n",
    "\tdf = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "\t# Sort the features by the absolute value of their coefficient\n",
    "\tdf[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "\tdf[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "\tdf = df.sort_values(\"abs_value\", ascending=False)\n",
    "\t# plot feature importance\n",
    "\tfig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\tsns.barplot(x=\"feature\",\n",
    "\t            y=\"value\",\n",
    "\t            data=df.head(20),\n",
    "\t           palette=df.head(20)[\"colors\"])\n",
    "\tplt.gcf().subplots_adjust(bottom=0.30)\n",
    "\tax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=14)\n",
    "\tax.set_title(\"Top 20 Features for {} w/ {}\".format(classifier.__class__.__name__, scaler_name), fontsize=25)\n",
    "\tax.set_ylabel(\"Coef\", fontsize=22)\n",
    "\tax.set_xlabel(\"Feature Name\", fontsize=22)\n",
    "\tplt.show()\n",
    "\n",
    "def evaluation(y, y_hat, title):\n",
    "\tcm = confusion_matrix(y, y_hat)\n",
    "\tprecision = precision_score(y, y_hat)\n",
    "\trecall = recall_score(y, y_hat)\n",
    "\taccuracy = accuracy_score(y,y_hat)\n",
    "\tf1 = f1_score(y,y_hat)\n",
    "\tprint('Recall: ', recall)\n",
    "\tprint('Accuracy: ', accuracy)\n",
    "\tprint('Precision: ', precision)\n",
    "\tprint('F1: ', f1)\n",
    "\tsns.heatmap(cm,  cmap= 'PuBu', annot=True, fmt='g', annot_kws=    {'size':20})\n",
    "\tplt.xlabel('predicted', fontsize=18)\n",
    "\tplt.ylabel('actual', fontsize=18)\n",
    "\tplt.title(title, fontsize=18)\n",
    "\tplt.show()\n",
    "    \n",
    "def metrics_summary(y_test,y_pred):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\taccuracy=accuracy_score(y_test, y_pred)\n",
    "\tprecision = precision_score(y_test, y_pred)\n",
    "\trecall =  recall_score(y_test, y_pred) #sensitivity\n",
    "\tspecificity = tn / (tn+fp)\n",
    "\tg_mean= sqrt(recall * specificity)\n",
    "\tmse =mean_squared_error(y_test, y_pred, squared=False)\n",
    "\tr2=r2_score(y_test, y_pred)\n",
    "\tros = roc_auc_score(y_test, y_pred)\n",
    "\tll = log_loss(y_test, y_pred)\n",
    "\tf1 = f1_score(y_test, y_pred)\n",
    "\t\n",
    "\tmetrics_collection_dict ={\n",
    "        'accuracy':['accuracy',accuracy],\n",
    "        'precision':['precision',precision],\n",
    "        'recall':['recall',recall],\n",
    "        'specificity':['specificity',specificity],\n",
    "        'g_mean':['g_mean',g_mean],\n",
    "        'mean_square_error':['mean_square_error',mse],\n",
    "        'r2':['r2',r2],\n",
    "        'roc_auc_score':['roc_auc_score',ros],\n",
    "        'log_loss':['log_loss',ll],\n",
    "        'f1_score':['f1_score',f1]\n",
    "    } \n",
    "\treturn metrics_collection_dict\n",
    "\n",
    "def correlationPlot():\n",
    "\tvisualizer = Rank2D(\n",
    "        features=X_train.columns, algorithm='covariance'\n",
    "    )\n",
    "\tvisualizer.fit(X_train, y_train)                # Fit the data to the visualizer\n",
    "\tvisualizer.transform(X_train)             # Transform the data\n",
    "\tvisualizer.show()                   # Finalize and render the figure\n",
    "\n",
    "def radVisualize():\n",
    "\tvisualizer = RadViz() #nice\n",
    "\tvisualizer.fit(X, y)\n",
    "\tvisualizer.transform(X)\n",
    "\tvisualizer.show()\n",
    "def pca_scatter_plot():\n",
    "\tvisualizer = pca_decomposition(X, y, scale=True, classes=['no','yes'])\n",
    "\tvisualizer.show()\n",
    "def precision_recall_curve(model):\n",
    "\tviz = PrecisionRecallCurve(model)\n",
    "\tviz.fit(X_train, y_train)\n",
    "\tviz.score(X_test, y_test)          #ok\n",
    "\tviz.show()\n",
    "    \n",
    "def overallClassificationReport(model,classes):\n",
    "\tvisualizer = ClassificationReport(model, classes=classes, support=True) #might can change\n",
    "\tvisualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "\tif(model.__class__.__name__ == \"XGBClassifier\"): #special treatment for xgboost as it reordered column\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\treorderedColumn = model.get_booster().feature_names\n",
    "\t\treordered_Xtest = X_test[reorderedColumn] #reorderColumn\n",
    "\t\tvisualizer.score(X_test, y_test)        \n",
    "\t\tvisualizer.show()\n",
    "\t\treturn\n",
    "\tvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "\tvisualizer.show()\n",
    "\n",
    "def class_predict_err_plot(model,classes):\n",
    "\tvisualizer = ClassPredictionError(model, classes=classes,encoder={1: 'yes',0: 'no'})\n",
    "\t# Fit the training data to the visualizer\n",
    "\tvisualizer.fit(X_train, y_train)\n",
    "\t# Evaluate the model on the test data\n",
    "\tvisualizer.score(X_test, y_test)\n",
    "\t# Draw visualization\n",
    "\tvisualizer.show()\n",
    "\n",
    "def learning_curve_plot(model):\n",
    "\tcv = StratifiedKFold(n_splits=12)\n",
    "\tsizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "\t# Instantiate the classification model and visualizer\n",
    "\tvisualizer = LearningCurve(\n",
    "\t    model, cv=cv, scoring='f1_weighted', train_sizes=sizes, n_jobs=4\n",
    "\t)\n",
    "\tvisualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "\tvisualizer.show()\n",
    "    \n",
    "def cv_scores_plot(model):\n",
    "\tcv = StratifiedKFold(n_splits=12, random_state=42, shuffle= True)\n",
    "\tvisualizer = CVScores(model, cv=cv, scoring='f1_weighted')\n",
    "\n",
    "\tvisualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "\tvisualizer.show()\n",
    "def overall_feature_importance(model):\n",
    "\tlabels = list(map(lambda s: s.title(), X.columns))\n",
    "\tviz = FeatureImportances(model, labels=labels,encoder={1: 'yes',0: 'no'}, relative=False, topn = 8)\n",
    "\tviz.fit(X, y)\n",
    "\tviz.show()\n",
    "def RFECV_plot(model):\n",
    "\tcv= StratifiedKFold(5)\n",
    "\t# Instantiate RFECV visualizer with a linear SVM classifier\n",
    "\tvisualizer = RFECV(model, cv= cv)\n",
    "\tvisualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "\tvisualizer.show()      #ok\n",
    "    \n",
    "def has_feature_imp(classifier):\n",
    "\tstatus = False\n",
    "\tif (hasattr(classifier,'coef_')):\n",
    "\t\tstatus = True\n",
    "\telif (hasattr(classifier,'coefs_')):\n",
    "\t\tstatus = True\n",
    "\telif (hasattr(classifier,'feature_importances_')):\n",
    "\t\tstatus = True\n",
    "\tprint(\"Cannot extract feature importance, skipping\")\n",
    "\treturn status\n",
    "\n",
    "def make_plot(item_idx):\n",
    "\ttitle, X = distributions[item_idx]\n",
    "\tax_zoom_out, ax_zoom_in, ax_colorbar = create_axes(title)\n",
    "\taxarr = (ax_zoom_out, ax_zoom_in)\n",
    "\tplot_distribution(axarr[0], X, y, hist_nbins=200,\n",
    "                      x0_label=\"Median Income\",\n",
    "                      x1_label=\"Number of households\",\n",
    "                      title=\"Full data\")\n",
    "\n",
    "\t# zoom-in\n",
    "\tzoom_in_percentile_range = (0, 99)\n",
    "\tcutoffs_X0 = np.percentile(X[:, 0], zoom_in_percentile_range)\n",
    "\tcutoffs_X1 = np.percentile(X[:, 1], zoom_in_percentile_range)\n",
    "\n",
    "\tnon_outliers_mask = (\n",
    "        np.all(X > [cutoffs_X0[0], cutoffs_X1[0]], axis=1) &\n",
    "        np.all(X < [cutoffs_X0[1], cutoffs_X1[1]], axis=1))\n",
    "\tplot_distribution(axarr[1], X[non_outliers_mask], y[non_outliers_mask],\n",
    "                      hist_nbins=50,\n",
    "                      x0_label=\"Median Income\",\n",
    "                      x1_label=\"Number of households\",\n",
    "                      title=\"Zoom-in\")\n",
    "\n",
    "\tnorm = mpl.colors.Normalize(y_full.min(), y_full.max())\n",
    "\tmpl.colorbar.ColorbarBase(ax_colorbar, cmap=cmap,\n",
    "                              norm=norm, orientation='vertical',\n",
    "                              label='Color mapping for values of y')\n",
    "    \n",
    "def scorer(pcamodel, X, y=None):\n",
    "    try:\n",
    "        X_val = X.values\n",
    "    except:\n",
    "        X_val = X\n",
    "    \n",
    "    try:\n",
    "        y_val = y.values\n",
    "    except:\n",
    "        y_val = y\n",
    "    data_inv = pcamodel.fit(X_val,y_val).transform(X_val)\n",
    "    reconstructed = pcamodel.inverse_transform(data_inv)\n",
    "    #find reconstrucition error\n",
    "    mse = mean_squared_error(reconstructed.ravel(), X_val.ravel())\n",
    "    return abs(mse)\n",
    "\n",
    "def pcaComparison(X_train,y_train,X_test,y_test):\n",
    "    cv=10\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(pcaX_train,y_train)\n",
    "    X_test_scaled = scaler.transform(pcaX_test)\n",
    "    pcaPerformance = pd.DataFrame()\n",
    "    for transformer in pcaParamGrid :\n",
    "        pca = transformer['transformer']\n",
    "        param_grid =  transformer['param_grid']\n",
    "        PCASearch = RandomizedSearchCV(pca,param_grid,n_iter=10,verbose=2,\n",
    "                         scoring= scorer,\n",
    "                         n_jobs=-1,cv=cv,random_state=42)\n",
    "        PCASearch = PCASearch.fit(X_train_scaled,y_train)\n",
    "\n",
    "        param = PCASearch.best_params_\n",
    "        name = PCASearch.best_estimator_.__class__.__name__\n",
    "        score = PCASearch.best_score_\n",
    "        pcaResult = {\"Model\":name,\"MSE\": score,\"Parameter\":param}\n",
    "        pcaPerformance = pcaPerformance.append(pcaResult,ignore_index=True)\n",
    "    pcaPerformance.sort_values(by='MSE',ascending=True,inplace=True)\n",
    "    return pcaPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxAAHzryNskR"
   },
   "outputs": [],
   "source": [
    "def cross_validate(classifier, cv):\n",
    "\tscalers = [StandardScaler(),MinMaxScaler(),MaxAbsScaler(), RobustScaler(),QuantileTransformer()]#quantile\n",
    "\ttrain_acc = []\n",
    "\ttest_acc = []\n",
    "\tmean = []\n",
    "\tresult = []\n",
    "\tfor scaler in scalers:\n",
    "\t\tfpr = None\n",
    "\t\ttpr = None\n",
    "\t\tpreprocess = setupPreprocessPipeline(scaler)\n",
    "\t\tpipeline = Pipeline(steps=[\n",
    "\t        ('preprocess', preprocess),\n",
    "\t        ('classifier', classifier)\n",
    "\t\t])\n",
    "\n",
    "\t\ttrain_acc = []\n",
    "\t\ttest_acc = []\n",
    "\t\tmean = []\n",
    "\n",
    "\t\tfor train_ind, val_ind in cv.split(X_train, y_train):\n",
    "\t\t\tX_t, y_t = X_train.iloc[train_ind], y_train.iloc[train_ind]\n",
    "\t\t\tpipeline.fit(X_t, y_t)\n",
    "\t\t\ty_hat_t = pipeline.predict(X_t)\n",
    "\t\t\ttrain_acc.append(accuracy_score(y_t, y_hat_t))\n",
    "\t\t\tX_val, y_val = X_train.iloc[val_ind], y_train.iloc[val_ind] \n",
    "\t\t\ty_hat_val = pipeline.predict(X_val)\n",
    "\t\t\ttest_acc.append(accuracy_score(y_val, y_hat_val))\n",
    "\n",
    "\t\t#ohe_cols = list(pipeline.named_steps['preprocess'].named_transformers_['cat'].named_steps['ohe'].get_feature_names(input_features=categorical))\n",
    "\t\tnumeric_feature_list = list(numerical)\n",
    "\t\tfor i in ohe_cols:\n",
    "\t\t\tnumeric_feature_list.append(i)\n",
    "\t\t#print(len(numeric_feature_list))\n",
    "\t\t#evaluation(y_val, y_hat_val, 'Confusion Matrix {} + {}'.format(classifier.__class__.__name__, scaler.__class__.__name__).strip())\n",
    "\t\tprint('Mean Training Accuracy: {} | Standard Deviation: {}'.format(np.mean(train_acc),np.std(test_acc)))\n",
    "\t\tprint('Mean Validation Accuracy: {} | Standard Deviation: {}'.format(np.mean(test_acc),np.std(test_acc)))\n",
    "\t\tprint('\\n')\n",
    "\t\tfeature_importance(classifier, numeric_feature_list, scaler.__class__.__name__ )\n",
    "\t\tmetrics_summ = metrics_summary(y_val,y_hat_val)\n",
    "\t\tif hasmethod(pipeline['classifier'], 'predict_proba'):\n",
    "\t\t\tfpr,tpr = ROC_Curve_Plot(pipeline,X_val,y_val,classifier.__class__.__name__ +\" w \"+scaler.__class__.__name__)\n",
    "\t\tresult.append({\n",
    "            'classifier':classifier.__class__.__name__,\n",
    "            'scalerName':scaler.__class__.__name__,\n",
    "            'metrics_summ':metrics_summ,\n",
    "            'fpr':fpr,\n",
    "            'tpr':tpr\n",
    "        })\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yjPnG_fn3XJ"
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "\t#Lasso(),\n",
    "\tSGDClassifier(max_iter = 1000, tol=1e-3,penalty = \"elasticnet\"),\n",
    "\tLinearSVC(), \n",
    "\tGaussianProcessClassifier(),\n",
    "\tExtraTreeClassifier(),   #guassiannb, guassian process, mlpclassifier, \n",
    "\tBernoulliNB(),\n",
    "\tLogisticRegressionCV(max_iter= 1200), \n",
    "\tRidgeClassifierCV(),\n",
    "\tSVC(kernel = 'linear',max_iter= -1), \n",
    "\tPerceptron(),\n",
    "\tPassiveAggressiveClassifier(), \n",
    "\tDecisionTreeClassifier(), #no coef \n",
    "\tKNeighborsClassifier(),#no feat_import, use permutation_importance \n",
    "\tGaussianNB(), #no feat_import, use permutation_importance \n",
    "\tLGBMClassifier(),#no coef \n",
    "\tRandomForestClassifier(), #no coef \n",
    "\tGradientBoostingClassifier(),#no coef \n",
    "\tPassiveAggressiveClassifier(), \n",
    "\tExtraTreesClassifier(), #no coef \n",
    "\tXGBClassifier(),\n",
    "\tAdaBoostClassifier(), #no coef\n",
    "# \tMLPClassifier() #mlp not working\n",
    "\t]\n",
    "\n",
    "model_result = []\n",
    "classes = [\"no\", \"yes\"]\n",
    "for model in models:\n",
    "\tprint(model.__class__.__name__)\n",
    "\tmodel_result.append(cross_validate(model,KFold()))\n",
    "\toverallClassificationReport(model,classes)\n",
    "\tif hasmethod(model, 'predict_proba'):\n",
    "\t\tROC_Curve_Plot(model,X_test,y_test,\"Overall \"+model.__class__.__name__)\n",
    "\tprecision_recall_curve(model)\n",
    "\tclass_predict_err_plot(model, classes=classes)\n",
    "\tlearning_curve_plot(model)\n",
    "\tcv_scores_plot(model)\n",
    "\tif has_feature_imp(model) :\n",
    "\t\toverall_feature_importance(model)\n",
    "\t\t#RFECV_plot(model)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFwBxRtVvJ4Z"
   },
   "outputs": [],
   "source": [
    "standardScalerList = []\n",
    "minMaxScalerList = []\n",
    "maxAbsScalerList = []\n",
    "robustScalerList = []\n",
    "QuantileTransformerList = []\n",
    "\n",
    "for collection in model_result:\n",
    "    standard = collection[0]\n",
    "    standardScalerList.append({'classifier':standard['classifier'],'metrics_summ':standard['metrics_summ'],'fpr':standard['fpr'],'tpr':standard['tpr'] })\n",
    "    minMax = collection[1]\n",
    "    minMaxScalerList.append({'classifier':minMax['classifier'],'metrics_summ':minMax['metrics_summ'],'fpr':minMax['fpr'],'tpr':minMax['tpr'] })\n",
    "    maxAbs = collection[2]\n",
    "    maxAbsScalerList.append({'classifier':maxAbs['classifier'],'metrics_summ':maxAbs['metrics_summ'],'fpr':maxAbs['fpr'],'tpr':maxAbs['tpr'] })\n",
    "    robust = collection[3]\n",
    "    robustScalerList.append({'classifier':robust['classifier'],'metrics_summ':robust['metrics_summ'],'fpr':robust['fpr'],'tpr':robust['tpr'] })\n",
    "    quantile = collection[4]\n",
    "    robustScalerList.append({'classifier':quantile['classifier'],'metrics_summ':quantile['metrics_summ'],'fpr':quantile['fpr'],'tpr':quantile['tpr'] })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6EUFBsRHLUp"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def metricsLoop():\n",
    "    nameList = []\n",
    "    summDF = pd.DataFrame()\n",
    "    \n",
    "    for object in model_result:\n",
    "        nameList.append(object[0]['classifier'])\n",
    "    metric_list = ['accuracy','precision','recall','specificity','g_mean'\n",
    "                   ,'mean_square_error','r2','roc_auc_score','log_loss','f1_score']\n",
    "\n",
    "    for i in range(5):\n",
    "        df = metricsCalc(i, model_result, metric_list, nameList,summDF)\n",
    "        cols_to_use = df.columns.difference(summDF.columns)\n",
    "        summDF = pd.concat([summDF, df], join=\"outer\")\n",
    "    return summDF\n",
    "\n",
    "def metricsCalc(modelNum, model_result, metric_list, nameList, summDF):\n",
    "    mainDF = pd.DataFrame()\n",
    "    for metric in metric_list:\n",
    "        resultList = []\n",
    "        \n",
    "        for model in model_result:\n",
    "            resultList.append(model[modelNum]['metrics_summ'][metric][1])\n",
    "        \n",
    "        accDF = pd.DataFrame(list(zip(nameList,resultList)),columns=['trained_model',metric])\n",
    "        ICD.display(accDF.sort_values(metric,ascending=False, ignore_index=True).head(8))\n",
    "    \n",
    "        if mainDF.empty is True:\n",
    "            mainDF = accDF\n",
    "        else:\n",
    "            cols_to_use = accDF.columns.difference(mainDF.columns)\n",
    "            mainDF = pd.concat([mainDF, accDF[cols_to_use]], axis=1, join=\"outer\")\n",
    "            \n",
    "    plt.title(\"Models' \"+metric+ \" with Min Max Scaler\")\n",
    "    ax = sns.barplot(data=accDF.sort_values(metric,ascending=False),orient='h',palette =\"Paired\" , y = 'trained_model',x=metric)\n",
    "    plt.show()\n",
    "    \n",
    "    switcher = {\n",
    "        0: '_SS',\n",
    "        1: '_MM',\n",
    "        2: '_MA',\n",
    "        3: '_RS',\n",
    "        4: '_QT'\n",
    "    }\n",
    "    mainDF['trained_model'] = mainDF['trained_model'].apply(lambda x: \"{}{}\".format(x, switcher.get(modelNum, \"\")))\n",
    "\n",
    "    return metricsAddSumm(mainDF, summDF)\n",
    "            \n",
    "def metricsAddSumm(mainDF, summDF):\n",
    "    ICD.display(mainDF.sort_values(by=['trained_model'],ascending=False, ignore_index=True))\n",
    "    mainDF = mainDF.drop(mainDF.columns[[4,5,6,7,9]],axis=1)\n",
    "    summDF = mainDF\n",
    "    \n",
    "    return summDF\n",
    "\n",
    "def saveDisplaySumm(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            switcher  = {\n",
    "                0: 'By Model Name',\n",
    "                1: 'By Accuracy',\n",
    "                2: 'By Precision',\n",
    "                3: 'By Recall',\n",
    "                4: 'By ROC-AUC Score',\n",
    "                5: 'By F1=Score'\n",
    "            }\n",
    "            df.to_excel(writer,switcher.get(n,''))\n",
    "        writer.save()\n",
    "    \n",
    "def metricsDisplaySumm(summDF): \n",
    "    dfList = []\n",
    "    dfList.append(summDF.sort_values(by=['trained_model'],ascending=False, ignore_index=True))\n",
    "    dfList.append(summDF.sort_values(by=['accuracy'],ascending=False, ignore_index=True))\n",
    "    dfList.append(summDF.sort_values(by=['precision'],ascending=False, ignore_index=True))\n",
    "    dfList.append(summDF.sort_values(by=['recall'],ascending=False, ignore_index=True))\n",
    "    dfList.append(summDF.sort_values(by=['roc_auc_score'],ascending=False, ignore_index=True))\n",
    "    dfList.append(summDF.sort_values(by=['f1_score'],ascending=False, ignore_index=True))\n",
    "    \n",
    "    saveDisplaySumm(dfList, r'.\\Detailed_Metrics_Score.xlsx')\n",
    "    \n",
    "#Generate Metrics Score DataFrames\n",
    "pd.DataFrame()\n",
    "summDF = metricsLoop()\n",
    "metricsDisplaySumm(summDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzI5diiIn3OT"
   },
   "outputs": [],
   "source": [
    "nameList = []\n",
    "\n",
    "for object in model_result:\n",
    "    nameList.append(object[0]['classifier'])\n",
    "metric_list = ['accuracy','precision','recall','specificity','g_mean'\n",
    "                   ,'mean_square_error','r2','roc_auc_score','log_loss','f1_score']\n",
    "scaler = ['Standard Scaler','Min Max Scaler','Max Abs Scaler','robust Scaler']\n",
    "for metric in metric_list:\n",
    "    resultList = []\n",
    "    for model in model_result:\n",
    "        resultList.append(model[0]['metrics_summ'][metric][1])\n",
    "        \n",
    "    accDF = pd.DataFrame(list(zip(nameList,resultList)),columns=['trained_model',metric])\n",
    "    plt.title(\"Models' \"+metric+ \" with Standard Scaler\")\n",
    "    ax = sns.barplot(data=accDF.sort_values(metric,ascending=False),orient='h',palette =\"Paired\" , y = 'trained_model',x=metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VHwPTf6n3ER"
   },
   "outputs": [],
   "source": [
    "for metric in metric_list:\n",
    "    resultList = []\n",
    "    for model in model_result:\n",
    "        resultList.append(model[1]['metrics_summ'][metric][1])\n",
    "        \n",
    "    accDF = pd.DataFrame(list(zip(nameList,resultList)),columns=['trained_model',metric])\n",
    "    plt.title(\"Models' \"+metric+ \" with Min Max Scaler\")\n",
    "    ax = sns.barplot(data=accDF.sort_values(metric,ascending=False),orient='h',palette =\"Paired\" , y = 'trained_model',x=metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiDEyUDbn26U"
   },
   "outputs": [],
   "source": [
    "for metric in metric_list:\n",
    "    resultList = []\n",
    "    for model in model_result:\n",
    "        resultList.append(model[2]['metrics_summ'][metric][1])\n",
    "        \n",
    "    accDF = pd.DataFrame(list(zip(nameList,resultList)),columns=['trained_model',metric])\n",
    "    plt.title(\"Models' \"+metric+ \" with Max Abs Scaler\")\n",
    "    ax = sns.barplot(data=accDF.sort_values(metric,ascending=False),orient='h',palette =\"Paired\" , y = 'trained_model',x=metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSsQdWSyn2gc"
   },
   "outputs": [],
   "source": [
    "\n",
    "for metric in metric_list:\n",
    "    resultList = []\n",
    "    for model in model_result:\n",
    "        resultList.append(model[3]['metrics_summ'][metric][1])\n",
    "        \n",
    "    accDF = pd.DataFrame(list(zip(nameList,resultList)),columns=['trained_model',metric])\n",
    "    plt.title(\"Models' \"+metric+ \" with Robust Scaler\")\n",
    "    ax = sns.barplot(data=accDF.sort_values(metric,ascending=False),orient='h',palette =\"Paired\" , y = 'trained_model',x=metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYgkEMBs7iyo"
   },
   "outputs": [],
   "source": [
    "\n",
    "for metric in metric_list:\n",
    "    resultList = []\n",
    "    for model in model_result:\n",
    "        resultList.append(model[4]['metrics_summ'][metric][1])\n",
    "        \n",
    "    accDF = pd.DataFrame(list(zip(nameList,resultList)),columns=['trained_model',metric])\n",
    "    plt.title(\"Models' \"+metric+ \" with Quantile Transformer\")\n",
    "    ax = sns.barplot(data=accDF.sort_values(metric,ascending=False),orient='h',palette =\"Paired\" , y = 'trained_model',x=metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeGnWf1goXwc"
   },
   "outputs": [],
   "source": [
    "scaler = ['Standard Scaler','Min Max Scaler','Max Abs Scaler','robust Scaler','QuantileTransformer']\n",
    "scalerIndex = [0,1,2,3,4]\n",
    "\n",
    "for scalerIndex, scalerName in zip(scalerIndex,scaler):\n",
    "    aucList=[]\n",
    "    result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "    for model in model_result:\n",
    "\n",
    "        fpr = model[scalerIndex]['fpr']\n",
    "        if(fpr is not None):\n",
    "            tpr = model[scalerIndex]['tpr']\n",
    "            auc = model[scalerIndex]['metrics_summ']['roc_auc_score'][1]\n",
    "            result_table = result_table.append({'classifiers':model[scalerIndex]['classifier'],\n",
    "                                            'fpr':fpr, \n",
    "                                            'tpr':tpr, \n",
    "                                            'auc':auc}, ignore_index=True)\n",
    "            aucList.append(auc)\n",
    "            \n",
    "    result_table.set_index('classifiers', inplace=True)\n",
    "    fontP = FontProperties()\n",
    "    fontP.set_size('large')\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    for i in result_table.index:\n",
    "        plt.plot(result_table.loc[i]['fpr'], \n",
    "                 result_table.loc[i]['tpr'], \n",
    "                 label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "    plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "    plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "    plt.title(scalerName+', ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "    plt.legend( title='Models', bbox_to_anchor=(1.05, 0.85), loc='upper left', prop=fontP)\n",
    "    plt.show()\n",
    "    print(\"Average auc scores : \"+str(np.average(aucList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRKbI1YwhTnk"
   },
   "outputs": [],
   "source": [
    "#plot correlationPlot\n",
    "correlationPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1RxUJtJhWfq"
   },
   "outputs": [],
   "source": [
    "#plot to test separatability of classes\n",
    "radVisualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4v9U9GwShXml"
   },
   "outputs": [],
   "source": [
    "#plot scatter plot\n",
    "pca_scatter_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8owuNouHzI8c"
   },
   "outputs": [],
   "source": [
    "#get data distribution from x train and train\n",
    "pd.options.plotting.backend = 'matplotlib'\n",
    "incomeNResponse = pd.concat([X_train[\"Income\"],y_train],axis=1)\n",
    "\n",
    "incomeNResponse[\"Response\"] = incomeNResponse[\"Response\"].replace(to_replace={0:\"No\",1:\"Yes\"})\n",
    "\n",
    "ax = incomeNResponse.boxplot(by=\"Response\")\n",
    "\n",
    "plt.Axes.set_xlabel(ax,\"Response\")\n",
    "plt.Axes.set_ylabel(ax,\"Income\")\n",
    "plt.suptitle(\"Boxplot of Income group by Responses\")\n",
    "\n",
    "\n",
    "axList = incomeNResponse.hist(column = \"Income\",by='Response')\n",
    "sns.set_context('notebook')\n",
    "plt.suptitle(\"Histogram of Income group by Responses\")\n",
    "\n",
    "\n",
    "for ax in axList.flatten():\n",
    "    plt.Axes.set_xlabel(ax,\"Income\")\n",
    "    plt.Axes.set_ylabel(ax,\"Count\")\n",
    "\n",
    "#get normalized income\n",
    "standardScaler = StandardScaler()\n",
    "normalizedXTrainIncome=standardScaler.fit_transform((incomeNResponse[\"Income\"].values).reshape(len(incomeNResponse),1))\n",
    "normalizedXTrainIncome = pd.DataFrame(normalizedXTrainIncome,columns=[\"Normalized_Income\"])\n",
    "normalizedXTestIncome = standardScaler.transform((X_test[\"Income\"].values).reshape(len(X_test),1))\n",
    "normalizedXTestIncome = pd.DataFrame(normalizedXTestIncome,columns=[\"Normalized_Income\"])\n",
    "incomeNResponse[\"Normalized_Income\"] = normalizedXTrainIncome\n",
    "\n",
    "ax = incomeNResponse.boxplot(column =\"Normalized_Income\", by=\"Response\")\n",
    "\n",
    "plt.Axes.set_xlabel(ax,\"Response\")\n",
    "plt.Axes.set_ylabel(ax,\"Income\")\n",
    "plt.suptitle(\"Boxplot of Normalized Income group by Responses\")\n",
    "\n",
    "\n",
    "axList = incomeNResponse.hist(column = \"Normalized_Income\",by='Response')\n",
    "sns.set_context('notebook')\n",
    "plt.suptitle(\"Histogram of Normalized Income group by Responses\")\n",
    "\n",
    "\n",
    "for ax in axList.flatten():\n",
    "    plt.Axes.set_xlabel(ax,\"Income\")\n",
    "    plt.Axes.set_ylabel(ax,\"Count\")\n",
    "pd.set_option('plotting.backend','pandas_bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKEWvPjIzJ3R"
   },
   "outputs": [],
   "source": [
    "#get data distribution from x train and train\n",
    "pd.options.plotting.backend = 'matplotlib'\n",
    "incomeNResponse = pd.concat([X_train[\"Income\"],y_train],axis=1)\n",
    "\n",
    "incomeNResponse[\"Response\"] = incomeNResponse[\"Response\"].replace(to_replace={0:\"No\",1:\"Yes\"})\n",
    "\n",
    "ax = incomeNResponse.boxplot(by=\"Response\")\n",
    "\n",
    "plt.Axes.set_xlabel(ax,\"Response\")\n",
    "plt.Axes.set_ylabel(ax,\"Income\")\n",
    "plt.suptitle(\"Boxplot of Income group by Responses\")\n",
    "\n",
    "\n",
    "axList = incomeNResponse.hist(column = \"Income\",by='Response')\n",
    "sns.set_context('notebook')\n",
    "plt.suptitle(\"Histogram of Income group by Responses\")\n",
    "\n",
    "\n",
    "for ax in axList.flatten():\n",
    "    plt.Axes.set_xlabel(ax,\"Income\")\n",
    "    plt.Axes.set_ylabel(ax,\"Count\")\n",
    "\n",
    "#get normalized income\n",
    "scaler = RobustScaler()\n",
    "normalizedXTrainIncome=scaler.fit_transform((incomeNResponse[\"Income\"].values).reshape(len(incomeNResponse),1))\n",
    "normalizedXTrainIncome = pd.DataFrame(normalizedXTrainIncome,columns=[\"Normalized_Income\"])\n",
    "normalizedXTestIncome = scaler.transform((X_test[\"Income\"].values).reshape(len(X_test),1))\n",
    "normalizedXTestIncome = pd.DataFrame(normalizedXTestIncome,columns=[\"Normalized_Income\"])\n",
    "incomeNResponse[\"Normalized_Income\"] = normalizedXTrainIncome\n",
    "\n",
    "ax = incomeNResponse.boxplot(column =\"Normalized_Income\", by=\"Response\")\n",
    "\n",
    "plt.Axes.set_xlabel(ax,\"Response\")\n",
    "plt.Axes.set_ylabel(ax,\"Income\")\n",
    "plt.suptitle(\"Boxplot of Normalized Income group by Responses\")\n",
    "\n",
    "\n",
    "axList = incomeNResponse.hist(column = \"Normalized_Income\",by='Response')\n",
    "sns.set_context('notebook')\n",
    "plt.suptitle(\"Histogram of Normalized Income group by Responses\")\n",
    "\n",
    "\n",
    "for ax in axList.flatten():\n",
    "    plt.Axes.set_xlabel(ax,\"Income\")\n",
    "    plt.Axes.set_ylabel(ax,\"Count\")\n",
    "pd.set_option('plotting.backend','pandas_bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvWansqoAm0p"
   },
   "outputs": [],
   "source": [
    "correlationPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZjWKi3vAoMW"
   },
   "source": [
    "Can conclude that most of the categorical columns are not high correlated.\n",
    "After selected features that present at here as wells as in top 5 models(based on f1-score),\n",
    "\n",
    "features of complain, acceptedcmp1, marital_absurd, acceptedcmp4 and acceptedcmp2 are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_xXlpZGbFtA"
   },
   "outputs": [],
   "source": [
    "#preserve index for possible future usage\n",
    "X_train_index =  X_train[\"index\"]\n",
    "X_test_index = X_test[\"index\"]\n",
    "\n",
    "#choose top 5 categorical features\n",
    "selectedCategorical = [\"Complain\",\"AcceptedCmp1\",\"Marital_Absurd\",\"AcceptedCmp4\",\"AcceptedCmp2\"]\n",
    "X_train = X_train[selectedCategorical]\n",
    "X_test = X_test[selectedCategorical]\n",
    "\n",
    "#add kmean column\n",
    "X_train[\"KMean\"]=kmeanTrainColumn\n",
    "X_test[\"KMean\"]=kmeanTestColumn\n",
    "\n",
    "#addPCA column\n",
    "kpcaCol = [\"PCA1\",\"PCA2\",\"PCA3\",\"PCA4\",\"PCA5\"]\n",
    "X_train[kpcaCol] = kpcaTrain\n",
    "X_test[kpcaCol] = kpcaTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-ktYuLqbFhd"
   },
   "outputs": [],
   "source": [
    "#Grid search params\n",
    "scoring = 'f1'\n",
    "fold=10\n",
    "featureNumList = list(range(1,X_train.shape[1]))\n",
    "modelsWithParam = [\n",
    "    {#not using adaboost here, it was an ensemble method\n",
    "        'model':XGBClassifier(),'param':{\n",
    "        'n_estimators':list(range(100,1000,100)),\n",
    "        'max_depth ':list(range(10,100,10)),\n",
    "        'learning_rate': [1.0,0.1,0.01,0.005,0.001,0.0005,0.0001],\n",
    "        'verbosity':[1],\n",
    "        'booster ':[\"gbtree\",\"gblinear\",\"dart\"],\n",
    "        'tree_method':[\"exact\",\"grow_local_histmaker\",\"approx\",\"gpu_hist\"],\n",
    "        'subsample':[0.8],\n",
    "        'colsample_bytree':[1],\n",
    "        'gamma':[1,0.1,0.01,0.005,0.001,0.0005,0.0001],\n",
    "        'num_parallel_tree':list(range(5,50,5)),\n",
    "        'importance_type':[\"gain\",\"weight\",\"cover\",\"total_gain\",\"total_cover\"],\n",
    "        'random_state': [42]\n",
    "        }\n",
    "},{\n",
    "        'model':LGBMClassifier(),'param':{\n",
    "        'boosting_type':[\"gbdt\",\"dart\",\"goss\",\"rf\"],\n",
    "        'metric':['binary_logloss'],\n",
    "        'sub_feature':list(np.arange(0.1,1,10)),\n",
    "        'num_leaves':list(range(10,50,10)),\n",
    "        'learning_rate': [1,0.1,0.01,0.005,0.001,0.0005,0.0001],\n",
    "        'n_estimators': list(range(100,1000,100)),\n",
    "        'min_data':[50],\n",
    "        'max_depth': list(range(5,20,5)),\n",
    "        'min_split_gain':list(np.arange(0.1,1,10)),\n",
    "        'random_state': [42]\n",
    "    }},{\n",
    "            \n",
    "        'model':SVC(),'param':{\n",
    "        'C': [ 1,0.1,10, 100, 1000],  \n",
    "        'gamma': [1,0.1,0.01,0.005,0.001,0.0005,0.0001], \n",
    "        'kernel': ['linear', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'random_state': [42] \n",
    "    }},\n",
    "    { #split svc into 2 as svc poly and non-poly kernel has\n",
    "        #different parameter\n",
    "        'model':SVC(),'param':{\n",
    "        'C': [0.1, 1, 10, 100, 1000],  \n",
    "        'gamma': [1,0.1,0.01,0.005,0.001,0.0005,0.0001], \n",
    "        'kernel': ['poly'],\n",
    "        'degree':[3,4,5,6],\n",
    "        'random_state': [42],\n",
    "    }},{#split logistic regression into as saga solver has different parameter needs\n",
    "        'model':LogisticRegressionCV(),'param':{'Cs': [[100,10,1, 0.1,0.05,0.001,0.0001]],#100,10,1, 0.1, 0.01, 0.001\n",
    "                                 'fit_intercept':[True,False],\n",
    "                                 'normalize':[True,False],\n",
    "                                 'dual':[True,False],\n",
    "                                 'penalty':['L2'],\n",
    "                                 'penalty':[True],\n",
    "                                 'max_iter':list(range(100,1000,100)),#[50,100,500,1000,2000,4000,8000]\n",
    "                                 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "                                 'random_state':[42]\n",
    "        }},\n",
    "        {\n",
    "        'model':LogisticRegressionCV(),'param':{'Cs': [[100,10,1, 0.1,0.05,0.001,0.0001]],#100,10,1, 0.1, 0.01, 0.001\n",
    "                                 'fit_intercept':[True,False],\n",
    "                                 'normalize':[True,False],\n",
    "                                 'penalty':['elasticnet'],\n",
    "                                 'penalty':[True],\n",
    "                                 'max_iter':list(range(100,1000,100)),#[50,100,500,1000,2000,4000,8000]\n",
    "                                 'solver':['saga'],\n",
    "                                 'random_state':[42]\n",
    "        }}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Gb4LMDsAwcP"
   },
   "outputs": [],
   "source": [
    "#gridsearchcv\n",
    "def modelBestFit(item):\n",
    "    model = item['model']\n",
    "    paramGrid = item['param']\n",
    "    search = GridSearchCV(model, paramGrid,n_jobs=-1,pre_dispatch='1*n_jobs',scoring = scoring,refit = True)\n",
    "    search.fit(X_train,y_train)\n",
    "    best_score =search.score(X_test,y_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    return {'model_name':model_name,'best_score':best_score,'best_model':search.best_estimator_}\n",
    "\n",
    "def bestModel(modelsAndParams):\n",
    "    modelPerformance = pd.DataFrame()\n",
    "    for item in modelsAndParams:\n",
    "        result = modelBestFit(item)\n",
    "        \n",
    "        modelPerformance = modelPerformance.append(result,ignore_index=True)\n",
    "        \n",
    "    modelPerformance.sort_values(by='best_score',ascending=False,inplace=True)\n",
    "    return modelPerformance\n",
    "    \n",
    "result = bestModel(modelsWithParam)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6Kj_TKMm84g"
   },
   "outputs": [],
   "source": [
    "#Randomized and bayesian search params\n",
    "scoring = 'f1'\n",
    "fold=10\n",
    "featureNumList = list(range(1,X_train.shape[1]))\n",
    "modelsWithParam = [\n",
    "    {#not using adaboost here, it was an ensemble method\n",
    "        'model':XGBClassifier(),'param':{\n",
    "        'n_estimators':list(range(100,1000,100)),\n",
    "        'max_depth ':list(range(10,100,10)),\n",
    "        'learning_rate': [1.0,0.1,0.01,0.005,0.001,0.0005,0.0001],\n",
    "        'verbosity':[1],\n",
    "        'booster ':[\"gbtree\",\"gblinear\",\"dart\"],\n",
    "        'tree_method':[\"exact\",\"grow_local_histmaker\",\"approx\",\"gpu_hist\"],\n",
    "        'subsample':[0.8],\n",
    "        'colsample_bytree':[1],\n",
    "        'gamma':[1,0.1,0.01,0.005,0.001,0.0005,0.0001],\n",
    "        'num_parallel_tree':list(range(5,50,5)),\n",
    "        'importance_type':[\"gain\",\"weight\",\"cover\",\"total_gain\",\"total_cover\"],\n",
    "        'random_state': [42]\n",
    "        }\n",
    "},{\n",
    "        'model':LGBMClassifier(),'param':{\n",
    "        'boosting_type':[\"gbdt\",\"dart\",\"goss\",\"rf\"],\n",
    "        'metric':['binary_logloss'],\n",
    "        'sub_feature':list(np.arange(0.1,1,10)),\n",
    "        'num_leaves':list(range(10,50,10)),\n",
    "        'learning_rate': [1,0.1,0.01,0.005,0.001,0.0005,0.0001],\n",
    "        'n_estimators': list(range(100,1000,100)),\n",
    "        'min_data':[50],\n",
    "        'max_depth': list(range(5,20,5)),\n",
    "        'min_split_gain':list(np.arange(0.1,1,10)),\n",
    "        'random_state': [42]\n",
    "    }},{\n",
    "            \n",
    "        'model':SVC(),'param':{\n",
    "        'C': [ 1,0.1,10, 100, 1000],  \n",
    "        'gamma': [1,0.1,0.01,0.005,0.001,0.0005,0.0001], \n",
    "        'kernel': ['linear', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'random_state': [42] \n",
    "    }},\n",
    "    { #split svc into 2 as svc poly and non-poly kernel has\n",
    "        #different parameter\n",
    "        'model':SVC(),'param':{\n",
    "        'C': [0.1, 1, 10, 100, 1000],  \n",
    "        'gamma': [1,0.1,0.01,0.005,0.001,0.0005,0.0001], \n",
    "        'kernel': ['poly'],\n",
    "        'degree':list(range(3,10)),\n",
    "        'random_state': [42],\n",
    "    }},{#split logistic regression into as saga solver has different parameter needs\n",
    "        'model':LogisticRegressionCV(),'param':{'Cs': [[100,10,1, 0.1,0.05,0.001,0.0001]],#100,10,1, 0.1, 0.01, 0.001\n",
    "                                 'fit_intercept':[True,False],\n",
    "                                 'normalize':[True,False],\n",
    "                                 'dual':[True,False],\n",
    "                                 'penalty':['L2'],\n",
    "                                 'penalty':[True],\n",
    "                                 'max_iter':list(range(100,1000,100)),#[50,100,500,1000,2000,4000,8000]\n",
    "                                 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "                                 'random_state':[42]\n",
    "        }},\n",
    "        {\n",
    "        'model':LogisticRegressionCV(),'param':{'Cs': [[100,10,1, 0.1,0.05,0.001,0.0001]],#100,10,1, 0.1, 0.01, 0.001\n",
    "                                 'fit_intercept':[True,False],\n",
    "                                 'normalize':[True,False],\n",
    "                                 'penalty':['elasticnet'],\n",
    "                                 'penalty':[True],\n",
    "                                 'max_iter':list(range(100,1000,100)),#[50,100,500,1000,2000,4000,8000]\n",
    "                                 'solver':['saga'],\n",
    "                                 'random_state':[42]\n",
    "        }}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoNS6Nn8m_cf"
   },
   "outputs": [],
   "source": [
    "#randomised search cv\n",
    "def modelBestFit(item):\n",
    "    model = item['model']\n",
    "    paramGrid = item['param']\n",
    "    search = RandomizedSearchCV(model, paramGrid,n_jobs=-1,pre_dispatch='1*n_jobs',scoring = scoring,refit = True,cv=fold)\n",
    "    search.fit(X_train,y_train)\n",
    "    best_score =search.score(X_test,y_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    return {'model_name':model_name,'best_score':best_score,'best_model':search.best_estimator_}\n",
    "\n",
    "def bestModel(modelsAndParams):\n",
    "    modelPerformance = pd.DataFrame()\n",
    "    for item in modelsAndParams:\n",
    "        result = modelBestFit(item)\n",
    "        \n",
    "        modelPerformance = modelPerformance.append(result,ignore_index=True)\n",
    "        \n",
    "    modelPerformance.sort_values(by='best_score',ascending=False,inplace=True)\n",
    "    return modelPerformance\n",
    " \n",
    "result = bestModel(modelsWithParam)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlKtak7OuE9C"
   },
   "outputs": [],
   "source": [
    "#bayesian search cv\n",
    "def modelBestFit(item,x_train,y_train,x_test,y_test):\n",
    "    model = item['model']\n",
    "    paramGrid = item['param']\n",
    "    search = BayesSearchCV(model, paramGrid,n_jobs=-1,pre_dispatch='1*n_jobs'\n",
    "                           ,scoring = scoring,refit = True,cv = fold)\n",
    "    search.fit(x_train,y_train)\n",
    "    best_score =search.score(x_test,y_test)\n",
    "    model_name = model.__class__.__name__\n",
    "    return {'model_name':model_name,'best_score':best_score,'best_model':search.best_estimator_}\n",
    "\n",
    "def bestModel(modelsAndParams,x_train,y_train,x_test,y_test):\n",
    "    modelPerformance = pd.DataFrame()\n",
    "    for item in modelsAndParams:\n",
    "        result = modelBestFit(item,x_train,y_train,x_test,y_test)\n",
    "        \n",
    "        modelPerformance = modelPerformance.append(result,ignore_index=True)\n",
    "        \n",
    "    modelPerformance.sort_values(by='best_score',ascending=False,inplace=True)\n",
    "    return modelPerformance\n",
    " \n",
    "result = bestModel(modelsWithParam)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverSamplingData(x,y):\n",
    "    oversampler = RandomOverSampler(sampling_strategy=0.5)\n",
    "    x,y = oversampler.fit_resample(x, y)\n",
    "    return (x,y)\n",
    "\n",
    "\n",
    "def getUnderSamplingData(x,y):\n",
    "    undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "    x,y = undersampler.fit_resample(x, y)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(classifier, cv,X_train,y_train,dtColumnStatus\n",
    "                   ,incomePreproStatus,IncomeEngiStatus,yearProcessStatus,dataSamplingStatus,numerical_no_bool):\n",
    "\tscalers = [StandardScaler(),MinMaxScaler(),MaxAbsScaler(), RobustScaler(),QuantileTransformer()]\n",
    "\ttrain_acc = []\n",
    "\ttest_acc = []\n",
    "\tmean = []\n",
    "\tresult = []\n",
    "\tfor scaler in scalers:\n",
    "\t\tpreprocess = setupPreprocessPipeline(scaler,numerical_no_bool)\n",
    "\t\tpipeline = Pipeline(steps=[\n",
    "\t        ('preprocess', preprocess),\n",
    "\t        ('classifier', classifier)\n",
    "\t\t])\n",
    "\t\ttrain_acc = []\n",
    "\t\ttest_acc = []\n",
    "\t\ttrain_recall = []\n",
    "\t\ttest_recall = []\n",
    "\t\ttrain_precision = []\n",
    "\t\ttest_precision = []\n",
    "\t\ttrain_f1 = []\n",
    "\t\ttest_f1 = []\n",
    "\t\ttrain_auc_roc = []\n",
    "\t\ttest_auc_roc = []\n",
    "\t\tmean = []\n",
    "\t\t\n",
    "\t\tfor train_ind, val_ind in cv.split(X_train, y_train):\n",
    "\t\t\tX_t, y_t = X_train.iloc[train_ind], y_train.iloc[train_ind]\n",
    "\t\t\tpipeline.fit(X_t, y_t)\n",
    "\t\t\ty_hat_t = pipeline.predict(X_t)\n",
    "\t\t\ttrain_acc.append(accuracy_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_recall.append(recall_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_precision.append(precision_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_f1.append(f1_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_auc_roc.append(roc_auc_score(y_t, y_hat_t))\n",
    "\t\t\tX_val, y_val = X_train.iloc[val_ind], y_train.iloc[val_ind] \n",
    "\t\t\ty_hat_val = pipeline.predict(X_val)\n",
    "\t\t\ttest_acc.append(accuracy_score(y_val, y_hat_val))\n",
    "\t\t\ttest_recall.append(recall_score(y_val, y_hat_val))\n",
    "\t\t\ttest_precision.append(precision_score(y_val, y_hat_val))\n",
    "\t\t\ttest_f1.append(f1_score(y_val, y_hat_val))\n",
    "\t\t\ttest_auc_roc.append(roc_auc_score(y_val, y_hat_val))\n",
    "\t\tmodel_result.append({\n",
    "            'classifier':classifier.__class__.__name__,\n",
    "            'scalerName':scaler.__class__.__name__,\n",
    "            'dataSampling':dataSamplingStatus,\n",
    "            'dtColumn':dtColumnStatus,\n",
    "            'incomePreprocessing':incomePreproStatus,\n",
    "            'IncomeEngineering':IncomeEngiStatus,\n",
    "            'yearProcess':yearProcessStatus,\n",
    "            'train_accuracy':np.mean(train_acc),\n",
    "            'test_accuracy':np.mean(test_acc),\n",
    "            'train_recall':np.mean(train_recall),\n",
    "            'test_recall':np.mean(test_recall),\n",
    "            'train_precision':np.mean(train_precision),\n",
    "            'test_precision':np.mean(test_precision),\n",
    "            'train_f1':np.mean(train_f1),\n",
    "            'test_f1':np.mean(test_f1),\n",
    "            'train_auc_roc':np.mean(train_auc_roc),\n",
    "            'test_auc_roc':np.mean(test_auc_roc)\n",
    "        })\n",
    "\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDcpYTm5MtQT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "# \tLasso(),\n",
    "\tSGDClassifier(max_iter = 1000, tol=1e-3,penalty = \"elasticnet\"),\n",
    "\tLinearSVC(), \n",
    "\tGaussianProcessClassifier(),\n",
    "\tExtraTreesClassifier(), \n",
    "# \tBernoulliNB(),\n",
    "\tLogisticRegressionCV(max_iter= 1200), \n",
    "\tRidgeClassifierCV(),\n",
    "\tSVC(kernel = 'linear',max_iter= -1), \n",
    "\tPerceptron(),\n",
    "\tPassiveAggressiveClassifier(), \n",
    "\tDecisionTreeClassifier(), #no coef \n",
    "\tKNeighborsClassifier(),#no feat_import, use permutation_importance \n",
    "\tGaussianNB(), #no feat_import, use permutation_importance \n",
    "\tLGBMClassifier(),#no coef \n",
    "\tRandomForestClassifier(), #no coef \n",
    "\tGradientBoostingClassifier(),#no coef \n",
    "\tPassiveAggressiveClassifier(), \n",
    "\tExtraTreesClassifier(), #no coef \n",
    "\tXGBClassifier(),\n",
    "\tAdaBoostClassifier(), #no coef\n",
    "# \tMLPClassifier() #mlp not working\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataSamplingMethod in getDataSampling(X,y):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MachineLearningPart1V2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
