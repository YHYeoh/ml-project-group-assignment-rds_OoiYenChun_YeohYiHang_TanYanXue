{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion \n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold, RandomizedSearchCV \n",
    "from sklearn.linear_model import Perceptron, LogisticRegressionCV, RidgeClassifierCV, SGDClassifier, PassiveAggressiveClassifier, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score,mean_absolute_error, confusion_matrix, silhouette_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc, classification_report,precision_score,recall_score,log_loss,f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, LabelEncoder, OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.preprocessing import MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer,minmax_scale,PolynomialFeatures\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn import tree\n",
    "import pandas_bokeh\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy import mean, std\n",
    "import pandas.testing as tm\n",
    "from scipy import stats\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer, SimpleImputer, KNNImputer\n",
    "\n",
    "from yellowbrick.features import PCA as PCA_YB\n",
    "from yellowbrick.features.radviz import RadViz\n",
    "from yellowbrick.features import pca_decomposition\n",
    "from yellowbrick.features import Manifold\n",
    "from yellowbrick.features import JointPlotVisualizer\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from yellowbrick.model_selection import CVScores\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.features import ParallelCoordinates\n",
    "from yellowbrick.model_selection import RFECV\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "\n",
    "#other\n",
    "from math import sqrt\n",
    "import inspect\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from scipy.stats import loguniform, uniform\n",
    "from bokeh import io\n",
    "import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import eli5\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Year_Birth', 'Education', 'Income', 'Kidhome', 'Teenhome',\n",
      "       'Dt_Customer', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts',\n",
      "       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
      "       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
      "       'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3',\n",
      "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',\n",
      "       'Complain', 'Z_CostContact', 'Z_Revenue', 'Response', 'Marital_Absurd',\n",
      "       'Marital_Alone', 'Marital_Divorced', 'Marital_Married',\n",
      "       'Marital_Single', 'Marital_Together', 'Marital_Widow', 'Marital_YOLO'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATASET_URL = \"https://gist.githubusercontent.com/YHYeoh/ad1a7f7170c72d621d05a70637540152/raw/5a6059c199e2c46d2f3d258f03d93cfea98e2749/marketing_campaign.csv\"\n",
    "data = pd.read_csv(DATASET_URL, sep = ';')\n",
    "\n",
    "education_order = [['Basic', 'Graduation', 'Master', '2n Cycle', 'PhD']]\n",
    "ordinal_encoder = OrdinalEncoder(categories=education_order)\n",
    "\n",
    "data[\"Education\"] = (ordinal_encoder.fit_transform(data[\"Education\"].values.reshape(-1, 1))).astype(int)\n",
    "# print(ordinal_encoder.categories_)\n",
    "\n",
    "#encode categorical column\n",
    "categorical = ['Marital_Status']\n",
    "marital_status_ohe = pd.get_dummies(data.Marital_Status,prefix=\"Marital\")\n",
    "data = data.join(marital_status_ohe)\n",
    "\n",
    "#drop original column after encoding\n",
    "data.drop(['Marital_Status'], axis = 1,inplace = True)\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "tunable_cols = [\"Year_Birth\", \"Income\",\"Dt_Customer\"]\n",
    "\n",
    "\n",
    "y = data.Response\n",
    "X = data.drop(\"Response\",axis=1)\n",
    "\n",
    "numerical_bool_col = [x for x in data.columns if data[x].isin([0,1]).all()] # print(numerical_bool_col)\n",
    "numerical_scalable_col = [x for x in data.columns if x not in numerical_bool_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer, SimpleImputer, KNNImputer\n",
    "\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "# import numba\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "def getKeyVal(inDict):\n",
    "  for i in inDict:\n",
    "    key=i\n",
    "    val= inDict[i]\n",
    "  return key,val\n",
    "\n",
    "def getIterativeImputedIncome(data):\n",
    "  imr = IterativeImputer(random_state=42, max_iter=100, min_value= data['Income'].min())\n",
    "  imr = imr.fit(data[['Income']])\n",
    "  data['Income'] = imr.transform(data[['Income']]).ravel()\n",
    "  return data\n",
    "\n",
    "def getKNNImputedIncome(data):\n",
    "\timputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\tdata = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\treturn data\n",
    "\n",
    "def getAgeFromDateBirth(data):\n",
    "\tyear = datetime.datetime.now().year\n",
    "\tdata['Year_Birth'] = data['Year_Birth'].apply(lambda x : year - x )\n",
    "\treturn data\n",
    "\n",
    "def extractFromDate(data):\n",
    "\tdata['enroll_year'] = pd.DatetimeIndex(data.Dt_Customer).year\n",
    "\tdata['enroll_month'] = pd.DatetimeIndex(data.Dt_Customer).month\n",
    "\tdata['enroll_day'] = pd.DatetimeIndex(data.Dt_Customer).day\n",
    "\tdata.drop(['Dt_Customer'], axis = 1, inplace= True)\n",
    "\treturn data\n",
    "\n",
    "def convertToDays(data):\n",
    "\tvfunc = np.vectorize(lambda x: (datetime.datetime.now() - x).days)\n",
    "\tdata['Dt_Customer'] = vfunc(pd.DatetimeIndex(data.Dt_Customer).to_pydatetime())\n",
    "\treturn data\n",
    "\n",
    "def getBinnedIncome(data):\n",
    "\tdata['Income'] = pd.cut(data['Income'], bins=[0, 15000, 60000, 110000, 700000], labels=False, precision=0).convert_dtypes()\n",
    "\treturn data\n",
    "\n",
    "def getNormalizedIncome(data):\n",
    "    \n",
    "\tdata = data[(np.abs(stats.zscore(data[['Income']])) < 3)]\n",
    "\treturn data\n",
    "\n",
    "def getNormalizedAndBinnedIncome(data):\n",
    "\tdata = data[(np.abs(stats.zscore(data[['Income']])) < 3)]\n",
    "\tdata['Income'] = pd.cut(data['Income'], bins=[0, 15000, 60000, 110000, 700000], labels=False, precision=0).convert_dtypes()\n",
    "\treturn data\n",
    "\n",
    "\n",
    "def getOverSamplingData(x,y):\n",
    "    oversampler = RandomOverSampler(sampling_strategy=0.5)\n",
    "    x,y = oversampler.fit_resample(x, y)\n",
    "    return (x,y)\n",
    "\n",
    "\n",
    "def getUnderSamplingData(x,y):\n",
    "    undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "    x,y = undersampler.fit_resample(x, y)\n",
    "    return (x,y)\n",
    "\n",
    "def getHypeYearBirth(data):\n",
    "\thyper_year_birth = [\n",
    "    {'Not age engineering':data},\n",
    "\t\t{'Age':getAgeFromDateBirth(data.copy())}\n",
    "\t]\n",
    "\treturn hyper_year_birth\n",
    "\n",
    "hyper_dt_customer = [\n",
    "\t{'extractFromDate':extractFromDate(data.copy())},\n",
    "\t{'convertToDays':convertToDays(data.copy())}\n",
    "]\n",
    "\n",
    "def getPreprocessingIncome(data):\n",
    "\tpreprocessing_income = [\n",
    "    {'getIterativeImputedIncome':getIterativeImputedIncome(data.copy())},\n",
    "\t\t{'getKNNImputedIncome':getKNNImputedIncome(data.copy())},\n",
    "\t\t{'fillNa method = ffill':data.copy().fillna(method = \"ffill\")}, #ffill\n",
    "\t\t{'fillNa method = bfill':data.copy().fillna(method = \"bfill\")}, #bfill\n",
    "\t\t{'mean imputed':data.copy().fillna(data.mean())}, #mean imputed\n",
    "\t\t{'median imputed':data.copy().fillna(data.median())}, #median imputed\n",
    "\t\t{'Income dropped':data.copy().dropna(subset=['Income'])}\n",
    "\t]\n",
    "\treturn preprocessing_income\n",
    "\n",
    "def getHypeIncome(data):\n",
    "\thyper_income = [\n",
    "  {'No income engineering':data},\n",
    "\t{'Binned Income':getBinnedIncome(data.copy())},\n",
    "\t{'Normalized Income':getNormalizedIncome(data.copy())},\n",
    "\t{'Binned and Normalized Income':getNormalizedAndBinnedIncome(data.copy())}\n",
    "\t]\n",
    "\treturn hyper_income\n",
    "\n",
    "\n",
    "def getDataSampling(x,y):\n",
    "\thyper_oversampling = [\n",
    "  {'No data sampling':(x,y)},\n",
    "\t{'Under sampling':getUnderSamplingData(x,y)},\n",
    "\t{'Over sampling':getOverSamplingData(x,y)},\n",
    "\t]\n",
    "\treturn hyper_oversampling\n",
    "\n",
    "\n",
    "# hyperparams = {\n",
    "# \t\"Year_Birth\":[ data['Year_Birth'], getAgeFromDateBirth(data.copy())],\t\n",
    "# \t\"Income\": [data['Income'], getBinnedIncome(data['Income']), getNormalizedIncome()]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasmethod(obj, name):\n",
    "\treturn inspect.ismethod(getattr(obj, name, None))\n",
    "\n",
    "def setupPreprocessPipeline(scaler,numerical_no_bool):\n",
    "\tss = Pipeline(steps=[('scaler',scaler)])\n",
    "\t#ohe = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "\tpreprocess = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('cont', ss, numerical_no_bool)\n",
    "                        #('cat', ohe, categorical),\n",
    "                        #('le', le, ordinal),\n",
    "                        ],remainder='passthrough')\n",
    "\treturn preprocess\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def overallClassificationReport(model,classes):\n",
    "\tvisualizer = ClassificationReport(model, classes=classes, support=True) #might can change\n",
    "\tvisualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "\tif(model.__class__.__name__ == \"XGBClassifier\"): #special treatment for xgboost as it reordered column\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\treorderedColumn = model.get_booster().feature_names\n",
    "\t\treordered_Xtest = X_test[reorderedColumn] #reorderColumn\n",
    "\t\tvisualizer.score(X_test, y_test)        \n",
    "\t\tvisualizer.show()\n",
    "\t\treturn\n",
    "\tvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "\tvisualizer.show()\n",
    "\n",
    "\n",
    "def overall_feature_importance(model,X_train,y_train):\n",
    "\tlabels = list(map(lambda s: s.title(), X.columns))\n",
    "\tviz = FeatureImportances(model, labels=labels,encoder={1: 'yes',0: 'no'}, relative=False, topn = 8)\n",
    "\tviz.fit(X, y)\n",
    "\tviz.show()\n",
    "\n",
    "def has_feature_imp(classifier):\n",
    "\tstatus = False\n",
    "\tif (hasattr(classifier,'coef_')):\n",
    "\t\tstatus = True\n",
    "\telif (hasattr(classifier,'coefs_')):\n",
    "\t\tstatus = True\n",
    "\telif (hasattr(classifier,'feature_importances_')):\n",
    "\t\tstatus = True\n",
    "\tprint(\"Cannot extract feature importance, skipping\")\n",
    "\treturn status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(classifier, cv,X_train,y_train,dtColumnStatus\n",
    "                   ,incomePreproStatus,IncomeEngiStatus,yearProcessStatus,dataSamplingStatus,numerical_no_bool):\n",
    "\tscalers = [StandardScaler(),MinMaxScaler(),MaxAbsScaler(), RobustScaler(),QuantileTransformer()]\n",
    "\ttrain_acc = []\n",
    "\ttest_acc = []\n",
    "\tmean = []\n",
    "\tresult = []\n",
    "\tfor scaler in scalers:\n",
    "\t\tpreprocess = setupPreprocessPipeline(scaler,numerical_no_bool)\n",
    "\t\tpipeline = Pipeline(steps=[\n",
    "\t        ('preprocess', preprocess),\n",
    "\t        ('classifier', classifier)\n",
    "\t\t])\n",
    "\n",
    "\t\ttrain_acc = []\n",
    "\t\ttest_acc = []\n",
    "\t\ttrain_recall = []\n",
    "\t\ttest_recall = []\n",
    "\t\ttrain_precision = []\n",
    "\t\ttest_precision = []\n",
    "\t\ttrain_f1 = []\n",
    "\t\ttest_f1 = []\n",
    "\t\ttrain_auc_roc = []\n",
    "\t\ttest_auc_roc = []\n",
    "\t\tmean = []\n",
    "\t\t\n",
    "\t\tfor train_ind, val_ind in cv.split(X_train, y_train):\n",
    "\t\t\tX_t, y_t = X_train.iloc[train_ind], y_train.iloc[train_ind]\n",
    "\t\t\tpipeline.fit(X_t, y_t)\n",
    "\t\t\ty_hat_t = pipeline.predict(X_t)\n",
    "\t\t\ttrain_acc.append(accuracy_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_recall.append(recall_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_precision.append(precision_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_f1.append(f1_score(y_t, y_hat_t))\n",
    "\t\t\ttrain_auc_roc.append(roc_auc_score(y_t, y_hat_t))\n",
    "\t\t\tX_val, y_val = X_train.iloc[val_ind], y_train.iloc[val_ind] \n",
    "\t\t\ty_hat_val = pipeline.predict(X_val)\n",
    "\t\t\ttest_acc.append(accuracy_score(y_val, y_hat_val))\n",
    "\t\t\ttest_recall.append(recall_score(y_val, y_hat_val))\n",
    "\t\t\ttest_precision.append(precision_score(y_val, y_hat_val))\n",
    "\t\t\ttest_f1.append(f1_score(y_val, y_hat_val))\n",
    "\t\t\ttest_auc_roc.append(roc_auc_score(y_val, y_hat_val))\n",
    "            \n",
    "\t\tmodel_result.append({\n",
    "            'classifier':classifier.__class__.__name__,\n",
    "            'scalerName':scaler.__class__.__name__,\n",
    "            'dataSampling':dataSamplingStatus,\n",
    "            'dtColumn':dtColumnStatus,\n",
    "            'incomePreprocessing':incomePreproStatus,\n",
    "            'IncomeEngineering':IncomeEngiStatus,\n",
    "            'yearProcess':yearProcessStatus,\n",
    "            'train_accuracy':np.mean(train_acc),\n",
    "            'test_accuracy':np.mean(test_acc),\n",
    "            'train_recall':np.mean(train_recall),\n",
    "            'test_recall':np.mean(test_recall),\n",
    "            'train_precision':np.mean(train_precision),\n",
    "            'test_precision':np.mean(test_precision),\n",
    "            'train_f1':np.mean(train_f1),\n",
    "            'test_f1':np.mean(test_f1),\n",
    "            'train_auc_roc':np.mean(train_auc_roc),\n",
    "            'test_auc_roc':np.mean(test_auc_roc)\n",
    "        })\n",
    "\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\t#Lasso(),\n",
    "# \tSGDClassifier(max_iter = 1000, tol=1e-3,penalty = \"elasticnet\"),\n",
    "# \tLinearSVC(), \n",
    "# \tGaussianProcessClassifier(),\n",
    "# \tExtraTreesClassifier(), \n",
    "# # \tBernoulliNB(),\n",
    "\tLogisticRegressionCV(max_iter= 1200), \n",
    "# \tRidgeClassifierCV(),\n",
    "\tSVC(kernel = 'linear',max_iter= -1), \n",
    "# \tPerceptron(),\n",
    "# \tPassiveAggressiveClassifier(), \n",
    "# \tDecisionTreeClassifier(), #no coef \n",
    "# \tKNeighborsClassifier(),#no feat_import, use permutation_importance \n",
    "# \tGaussianNB(), #no feat_import, use permutation_importance \n",
    "\tLGBMClassifier(),#no coef \n",
    "\tRandomForestClassifier(), #no coef \n",
    "# \tGradientBoostingClassifier(),#no coef \n",
    "# \tPassiveAggressiveClassifier(), \n",
    "# \tExtraTreesClassifier(), #no coef \n",
    "\tXGBClassifier(),\n",
    "# \tAdaBoostClassifier(), #no coef\n",
    "# \tMLPClassifier() #mlp not working\n",
    "\t]\n",
    "tunable_cols = [\"Year_Birth\", \"Income\",\"Dt_Customer\"]\n",
    "model_result= []\n",
    "classes = [\"no\", \"yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "problemSet=None;\n",
    "counter=0;\n",
    "for processed_dt_cust in hyper_dt_customer:\n",
    "  dtColumnMethod,data= getKeyVal(processed_dt_cust)\n",
    "  for preprocessed_income in getPreprocessingIncome(data):\n",
    "    incomePreprocessMethod,data= getKeyVal(preprocessed_income)\n",
    "    for processed_income_col in getHypeIncome(data):\n",
    "      incomeEngineeringMethod,data= getKeyVal(processed_income_col)\n",
    "      for processed_year_birth in getHypeYearBirth(data):\n",
    "        processYearMethod,data = getKeyVal(processed_year_birth) # print(data)\n",
    "        numerical_bool_col = [x for x in data.columns if data[x].isin([0,1]).all()] # print(numerical_bool_col)\n",
    "        numerical_scalable_col = [x for x in data.columns if x not in numerical_bool_col]\n",
    "        y = data.Response # print(y.value_counts())\n",
    "        X = data.drop(['Response'], axis=1)\n",
    "        #should auto drop columns based on pearson correlation , feature importance\n",
    "        #X.drop(['NumStorePurchases','NumCatalogPurchases','MntFruits','MntFishProducts','MntSweetProducts','MntWines'], axis = 1, inplace = True)\n",
    "        \n",
    "\n",
    "    #             print(\"Dt                : \",dtColumnMethod,\"\\n\")\n",
    "    #             print(\"Preprocess Income : \",incomePreprocessMethod,\"\\n\")\n",
    "    #             print(\"Income Engineering: \",incomeEngineeringMethod,\"\\n\")\n",
    "    #             print(\"Process Year      : \",processYearMethod,\"\\n\") # print(numerical_scalable_col) # print(data.info())\n",
    "    #             print(\"Data Sampling     : \",dataSamplingDesc,\"\\n\")\n",
    "              \n",
    "      \n",
    "        for model in models:\n",
    "            x_dropped_data = X.drop([x for x in X.columns if x not in classifier_columns[model.__class__.__name__]],axis = 1)\n",
    "            nummerical_no_bool = [x for x in numerical_scalable_col if x in x_dropped_data.columns]\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(x_dropped_data,y, test_size=0.25, random_state=42)\n",
    "            for dataSamplingMethod in getDataSampling(X_train,y_train):\n",
    "              dataSamplingDesc,data= getKeyVal(dataSamplingMethod)\n",
    "              X_train,y_train = data\n",
    "#             print(X_train.isnull().values.any(),y_train.isnull().values.any(),\"\\n\")\n",
    "              if(X_train.isnull().values.any()==True):\n",
    "                  problemSet = X_train\n",
    "                  print(X_train.isnull())\n",
    "                  break\n",
    "              counter+=1\n",
    "              if(counter%100==0):\n",
    "                  print(\"Counter : \",counter)\n",
    "              model_result.append(cross_validate(model,StratifiedKFold(),X_train,y_train,dtColumnMethod,incomePreprocessMethod\n",
    "                                                    ,incomeEngineeringMethod,processYearMethod,dataSamplingDesc,nummerical_no_bool))\n",
    "  #                 overallClassificationReport(model,classes)\n",
    "#                 if hasmethod(model, 'predict_proba'):\n",
    "#                     ROC_Curve_Plot(model,X_test,y_test,\"Overall \"+model.__class__.__name__)\n",
    "#                 if has_feature_imp(model) :\n",
    "#                     overall_feature_importance(model,X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF = pd.DataFrame.from_records(model_result,columns=['classifier','scalerName','dataSampling','dtColumn'\n",
    "                                                           ,'incomePreprocessing','IncomeEngineering','yearProcess'\n",
    "                                                           ,'train_accuracy','test_accuracy','train_recall','test_recall'\n",
    "                                                           ,'train_precision','test_precision','train_f1','test_f1',\n",
    "                                                          'train_roc_auc','test_roc_auc'])\n",
    "resultDF=resultDF.dropna(how='all')\n",
    "\n",
    "# roc_auc\n",
    "# f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultDF.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accColumn=['classifier','scalerName','dataSampling','dtColumn','incomePreprocessing','IncomeEngineering','yearProcess','train_accuracy','test_accuracy']\n",
    "resultDF[accColumn].sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recallColumn=['classifier','scalerName','dataSampling','dtColumn','incomePreprocessing','IncomeEngineering','yearProcess','train_recall','test_recall']\n",
    "resultDF[recallColumn].sort_values('test_recall',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precColumn=['classifier','scalerName','dataSampling','dtColumn','incomePreprocessing','IncomeEngineering','yearProcess','train_precision','test_precision']\n",
    "resultDF[precColumn].sort_values('test_precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1Column=['classifier','scalerName','dataSampling','dtColumn','incomePreprocessing','IncomeEngineering','yearProcess','train_f1','test_f1']\n",
    "resultDF[f1Column].sort_values('test_f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_aucColumn=['classifier','scalerName','dataSampling','dtColumn','incomePreprocessing','IncomeEngineering','yearProcess','train_roc_auc','test_roc_auc']\n",
    "resultDF[roc_aucColumn].sort_values('test_roc_auc',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc xgb, rfc, lgbm, logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scoring = 'f1'\n",
    "fold=10\n",
    "# featureNumList = list(range(1,X_train.shape[1]))\n",
    "modelsWithParam = [\n",
    "         { \n",
    "        'model':LogisticRegression(),'param':{'C': np.logspace(-3,3,7),#100,10,1, 0.1, 0.01, 0.001\n",
    "#                                  'fit_intercept':[True,False],\n",
    "#                                  'dual':[True,False],\n",
    "#                                  'penalty':['l2'],\n",
    "#                                  'max_iter':list(range(100,1000,100)),#[50,100,500,1000,2000,4000,8000]\n",
    "#                                  'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "        }},\n",
    "    {\n",
    "        'model':LGBMClassifier(),'param':{\n",
    "        'boosting_type':[\"gbdt\",\"dart\",\"goss\",\"rf\"],\n",
    "        'metric':['binary_logloss'],\n",
    "#         'sub_feature':list(np.arange(0.1,1,10)),\n",
    "#         'num_leaves':list(range(10,50,10)),\n",
    "#         'learning_rate': [1,0.1,0.01,0.005,0.001],\n",
    "#         'n_estimators': list(range(100,1000,100)),\n",
    "#         'min_data':[50],\n",
    "#         'max_depth': list(range(5,20,5)),\n",
    "#         'min_split_gain':list(np.arange(0.1,1,10)),\n",
    "#         'random_state': [42]\n",
    "    }},\n",
    "    {\n",
    "        'model':RandomForestClassifier(),'param':{\n",
    "            'bootstrap': [True, False],\n",
    "#              'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#              'max_features': ['auto', 'sqrt'],\n",
    "#              'min_samples_leaf': [1, 2, 4],\n",
    "#              'min_samples_split': [2, 5, 10],\n",
    "#              'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "    }},\n",
    "    {\n",
    "        'model':XGBClassifier(),'param':{\n",
    "            'n_estimators': [400] #, 700, 1000],\n",
    "#             'colsample_bytree': [0.7, 0.8],\n",
    "#             'max_depth': [15,20,25],\n",
    "#             'reg_alpha': [1.1, 1.2, 1.3],\n",
    "#             'reg_lambda': [1.1, 1.2, 1.3],\n",
    "#             'subsample': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "            \n",
    "        'model':SVC(),'param':{\n",
    "         'C': [ 1,0.1] #,10, 100, 1000],  \n",
    "#         'gamma': [0.0001,0.00001], \n",
    "#         'kernel': ['linear', 'rbf'],\n",
    "#         'random_state': [42] \n",
    "    }}\n",
    "    \n",
    "    \n",
    "    \n",
    "#     { split svc into 2 as svc poly and non-poly kernel has\n",
    "#         #different parameter\n",
    "#         'model':SVC(),'param':{\n",
    "#         'C': [0.1, 1, 10, 100, 1000],  \n",
    "#         'gamma': [1,0.1,0.01,0.005,0.001,0.0005,0.0001], \n",
    "#         'kernel': ['poly'],\n",
    "#         'degree':list(range(3,10)),\n",
    "#         'random_state': [42],\n",
    "#     }}\n",
    "\n",
    "#         {\n",
    "#         'model':LogisticRegression(),'param':{'Cs': [[100,10,1, 0.1,0.05,0.001,0.0001]],#100,10,1, 0.1, 0.01, 0.001\n",
    "#                                  'fit_intercept':[True,False],\n",
    "#                                  'normalize':[True,False],\n",
    "#                                  'penalty':['elasticnet'],\n",
    "#                                  'penalty':[True],\n",
    "#                                  'max_iter':list(range(100,1000,100)),#[50,100,500,1000,2000,4000,8000]\n",
    "#                                  'solver':['saga'],\n",
    "#                                  'random_state':[42]\n",
    "#         }}\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines column to drop for each classifier\n",
    "classifier_columns = {\n",
    "\t\t\"SVC\":[\"AcceptedCmp2\",\"AcceptedCmp5\",\"MntSweetProducts\",\"Complain\",\"MntWines\",\"Year_Birth\",\"MntGoldProds\",\"NumDealsPurchases\"],\n",
    "\t\t\"LGBMClassifier\":[\"Kidhome\",\"MntWines\",\"Education\",\"Teenhome\",\"AcceptedCmp4\",\"MntFishProducts\",\"AcceptedCmp2\",\"AcceptedCmp5\"],\n",
    "\t\t\"RandomForestClassifier\":[\"Kidhome\",\"Teenhome\",\"Education\",\"MntWines\",\"MntFishProducts\",\"AcceptedCmp4\",\"AcceptedCmp5\",\"AcceptedCmp2\"],\n",
    "\t\t\"XGBClassifier\":[\"AcceptedCmp2\",\"AcceptedCmp5\",\"Complain\",\"Marital_Together\",\"Marital_Married\",\"NumDealsPurchases\",\"Kidhome\",\"Year_Birth\"],\n",
    "\t\t\"LogisticRegression\":[\"AcceptedCmp2\",\"AcceptedCmp5\",\"Complain\",\"AcceptedCmp1\",\"enroll_year\",\"Marital_Married\",\"Marital_Together\",\"Year_Birth\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 100)\n",
      "(560, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py:289: UserWarning: The total space of parameters 7 is smaller than n_iter=200. Running 7 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py:289: UserWarning: The total space of parameters 4 is smaller than n_iter=200. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'LogisticRegression', 'test_score': 0.8392857142857143, 'best_score': 0.7644320297951583, 'best_model': LogisticRegression(C=1000.0)}\n",
      "(2148, 100)\n",
      "(560, 100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ffe3ec646d06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodelPerformance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelsWithParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-ffe3ec646d06>\u001b[0m in \u001b[0;36mbestModel\u001b[1;34m(modelsAndParams)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelBestFit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_transformed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mmodelPerformance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelPerformance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ffe3ec646d06>\u001b[0m in \u001b[0;36mmodelBestFit\u001b[1;34m(item, X_trains, y_trains, X_tests, y_tests)\u001b[0m\n\u001b[0;32m     10\u001b[0m                                 \u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                 ,random_state=42)\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trains\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_trains\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tests\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1619\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1621\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#randomised search cv\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "scoring = \"accuracy\"\n",
    "fold=4\n",
    "def modelBestFit(item,X_trains,y_trains,X_tests,y_tests):\n",
    "    model = item['model']\n",
    "    paramGrid = item['param']\n",
    "    search = RandomizedSearchCV(estimator=model, param_distributions= paramGrid\n",
    "                                ,n_iter=200,n_jobs=-1,pre_dispatch='1*n_jobs'\n",
    "                                ,scoring = scoring,refit = True,cv=fold\n",
    "                                ,random_state=42)\n",
    "    search.fit(X_trains,y_trains.values)\n",
    "    test_score =search.score(X_tests,y_tests.values)\n",
    "    model_name = model.__class__.__name__\n",
    "    return {'model_name':model_name,'test_score':test_score,'best_score':search.best_score_,'best_model':search.best_estimator_}\n",
    "\n",
    "def bestModel(modelsAndParams):\n",
    "    modelPerformance = pd.DataFrame()\n",
    "    for item in modelsAndParams:\n",
    "        \n",
    "        model = item['model']\n",
    "        \n",
    "        x_copy = X.copy()\n",
    "        x_copy = x_copy.drop([x for x in x_copy.columns if x not in classifier_columns[model.__class__.__name__]],axis = 1)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(x_copy,y, test_size=0.25, random_state=42)\n",
    "        \n",
    "        X_train= X_train.fillna(method = \"ffill\")\n",
    "        X_test = X_test.fillna(method = \"ffill\")\n",
    "        \n",
    "        if('Dt_Customer' in x_copy.columns):\n",
    "            X_train = extractFromDate(X_train)\n",
    "            X_test = extractFromDate(X_test)\n",
    "        \n",
    "        if('Income' in x_copy.columns):\n",
    "            X_train = getNormalizedAndBinnedIncome(X_train)\n",
    "            X_test = getNormalizedAndBinnedIncome(X_test)\n",
    "        \n",
    "        y_train = y_train[y_train.index.isin(X_train.index)]\n",
    "        y_test = y_test[y_test.index.isin(X_test.index)]\n",
    "        oversampler = RandomOverSampler(sampling_strategy=0.5,random_state=42)\n",
    "        X_train,y_train = oversampler.fit_resample(X_train, y_train)\n",
    "        \n",
    "        qt = QuantileTransformer(random_state=42)\n",
    "        X_train = qt.fit_transform(X_train)\n",
    "        X_test = qt.transform(X_test)\n",
    "        \n",
    "        nystroem = Nystroem()\n",
    "        \n",
    "        X_train_transformed = nystroem.fit_transform(X_train)\n",
    "        X_test_transformed = nystroem.transform(X_test)\n",
    "\n",
    "        print(X_train_transformed.shape)\n",
    "        print(X_test_transformed.shape)\n",
    "\n",
    "        result = modelBestFit(item,X_train_transformed,y_train,X_test_transformed,y_test)\n",
    "        modelPerformance = modelPerformance.append(result,ignore_index=True)\n",
    "        print(result)\n",
    "        \n",
    "    modelPerformance.sort_values(by='test_score',ascending=False,inplace=True)\n",
    "    return modelPerformance\n",
    " \n",
    "result = bestModel(modelsWithParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Type :  hard\n",
      "Classifiers:  SVC LogisticRegression LGBMClassifier\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Type :  soft\n",
      "Classifiers:  LogisticRegression LGBMClassifier\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "softHardClassificationReport(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def softHardClassificationReport(result):\n",
    "    top_3 = result.sort_values(by='test_score',ascending=False).head(n=3)\n",
    "    top_3 = top_3.reset_index().drop('index',axis=1)\n",
    "    nofOfClassifier=3\n",
    "    classList = []\n",
    "    best_model_name = top_3['model_name'][0]\n",
    "    topColumns = classifier_columns[best_model_name]\n",
    "\n",
    "\n",
    "    x_copy = X.copy()\n",
    "    x_copy = x_copy.drop([x for x in x_copy.columns if x not in classifier_columns[best_model_name]],axis = 1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_copy,y, test_size=0.25, random_state=42)\n",
    "\n",
    "    X_train= X_train.fillna(method = \"ffill\")\n",
    "    X_test = X_test.fillna(method = \"ffill\")\n",
    "\n",
    "    if('Dt_Customer' in x_copy.columns):\n",
    "        X_train = extractFromDate(X_train)\n",
    "        X_test = extractFromDate(X_test)\n",
    "\n",
    "    if('Income' in x_copy.columns):\n",
    "        X_train = getNormalizedAndBinnedIncome(X_train)\n",
    "        X_test = getNormalizedAndBinnedIncome(X_test)\n",
    "\n",
    "    y_train = y_train[y_train.index.isin(X_train.index)]\n",
    "    y_test = y_test[y_test.index.isin(X_test.index)]\n",
    "    oversampler = RandomOverSampler(sampling_strategy=0.5,random_state=42)\n",
    "    X_train,y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    qt = QuantileTransformer(random_state=42)\n",
    "    X_train = qt.fit_transform(X_train)\n",
    "    X_test = qt.transform(X_test)\n",
    "\n",
    "    nystroem = Nystroem()\n",
    "\n",
    "    X_train_transformed = nystroem.fit_transform(X_train)\n",
    "    X_test_transformed = nystroem.transform(X_test)\n",
    "\n",
    "\n",
    "    for i in range(nofOfClassifier):\n",
    "        model_name = top_3['model_name'][i]\n",
    "        model = top_3['best_model'][i]\n",
    "        classList.append((model_name,model))\n",
    "        votingOption=['hard','soft']\n",
    "\n",
    "    for voteType in votingOption:\n",
    "        votingClassifierReport(classList,voteType,X_train_transformed,y_train,X_test_transformed,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324     0\n",
      "96      0\n",
      "2104    0\n",
      "1259    0\n",
      "1061    0\n",
      "       ..\n",
      "2185    0\n",
      "1995    1\n",
      "305     0\n",
      "209     1\n",
      "1511    0\n",
      "Name: Response, Length: 560, dtype: int64\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_data=50. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=1.0, will be overridden by sub_feature=0.1. Current value: feature_fraction=0.1\n",
      "Train roc_auc_Score :  0.6847067039106145\n",
      "Train roc_auc_Score :  0.5803895594151702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "classList = [(('SVC',SVC(C=1000, gamma=0.0001, kernel='linear', random_state=42))),\n",
    "            (('LogisticRegression',LogisticRegression(C=100.0, solver='newton-cg'))),\n",
    "            ('LGBMClassifier',LGBMClassifier(max_depth=15, metric='binary_logloss', min_data=50,\n",
    "               min_split_gain=0.1, n_estimators=800, num_leaves=40,\n",
    "               random_state=42, sub_feature=0.1))]\n",
    "\n",
    "best_model_name = 'SVC'\n",
    "topColumns = classifier_columns['SVC']\n",
    "\n",
    "\n",
    "x_copy = X.copy()\n",
    "x_copy = x_copy.drop([x for x in x_copy.columns if x not in classifier_columns[best_model_name]],axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_copy,y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train= X_train.fillna(method = \"ffill\")\n",
    "X_test = X_test.fillna(method = \"ffill\")\n",
    "\n",
    "if('Dt_Customer' in x_copy.columns):\n",
    "    X_train = extractFromDate(X_train)\n",
    "    X_test = extractFromDate(X_test)\n",
    "\n",
    "if('Income' in x_copy.columns):\n",
    "    X_train = getNormalizedAndBinnedIncome(X_train)\n",
    "    X_test = getNormalizedAndBinnedIncome(X_test)\n",
    "\n",
    "y_train = y_train[y_train.index.isin(X_train.index)]\n",
    "y_test = y_test[y_test.index.isin(X_test.index)]\n",
    "oversampler = RandomOverSampler(sampling_strategy=0.5,random_state=42)\n",
    "X_train,y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "qt = QuantileTransformer(random_state=42)\n",
    "X_train = qt.fit_transform(X_train)\n",
    "X_test = qt.transform(X_test)\n",
    "\n",
    "nystroem = Nystroem()\n",
    "\n",
    "X_train_transformed = nystroem.fit_transform(X_train)\n",
    "X_test_transformed = nystroem.transform(X_test)\n",
    "\n",
    "print(y_test)\n",
    "# for i in range(3):\n",
    "#     model_name = top_3['model_name'][i]\n",
    "#     model = top_3['best_model'][i]\n",
    "#     classList.append((model_name,model))\n",
    "#     votingOption=['hard','soft']\n",
    "votingOption=['hard','soft']\n",
    "# print(X_train_transformed.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "\n",
    "# print(X_test_transformed.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "voting = VotingClassifier(estimators=classList, voting='hard')\n",
    "voting = voting.fit(X_train_transformed,y_train)\n",
    "train_predict = voting.predict(X_train_transformed)\n",
    "print(\"Train roc_auc_Score : \",roc_auc_score(y_train, train_predict))\n",
    "test_predict = voting.predict(X_test_transformed)\n",
    "print(\"Train roc_auc_Score : \",roc_auc_score(y_test, test_predict))\n",
    "\n",
    "\n",
    "# votingClassifierReport(classList,'hard',X_train_transformed,y_train,X_test_transformed,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "def overallClassificationReport(model,classes,X_train,y_train,X_test,y_test):\n",
    "\tvisualizer = ClassificationReport(model, classes=classes, support=True) #might can change\n",
    "\tvisualizer.fit(X_train, y_train.values.reshape(-1, 1))        # Fit the visualizer and the model\n",
    "\tvisualizer.score(X_test, y_test.values)        # Evaluate the model on the test data\n",
    "\tvisualizer.show()\n",
    "def votingClassifierReport(classifiers,votingT,X_train,y_train,X_test,y_test):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    usableClassifier = []\n",
    "    if(votingT =='soft'):\n",
    "        for i in classifiers:\n",
    "            if hasattr(i[1],'predict_proba'):\n",
    "                usableClassifier.append(i)\n",
    "    else:\n",
    "        usableClassifier = classifiers\n",
    "    classes =['no','yes']\n",
    "    #majority voting\n",
    "#     in_use_classifiers=\"\"\n",
    "#     for i in classifiers:\n",
    "#         in_use_classifiers = in_use_classifiers+\" \"+str(i[1].__class__.__name__)\n",
    "#     print(\"Voting Type : \",votingT)\n",
    "#     print(\"Classifiers: \"+in_use_classifiers)\n",
    "    voting = VotingClassifier(estimators=classifiers, voting='hard')\n",
    "#     voting.train\n",
    "#     pkl_filename = \"{}votingClassifier.pkl\".format(votingT)\n",
    "# #     if os.path.exists(pkl_filename):\n",
    "#         with open(pkl_filename, 'rb') as file:  \n",
    "#             voting = pickle.load(file)\n",
    "#     else:\n",
    "#         voting = voting.fit(X_train,y_train)\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    \n",
    "    voting = voting.fit(X_train,y_train)\n",
    "    train_predict = voting.predict(X_train)\n",
    "    print(\"Train roc_auc_Score : \",roc_auc_score(y_train, train_predict))\n",
    "    test_predict = voting.predict(X_test)\n",
    "    print(\"Train roc_auc_Score : \",roc_auc_score(y_test, test_predict))\n",
    "#     with open(pkl_filename, 'wb') as file:\n",
    "#         pickle.dump(model, file)\n",
    "#     overallClassificationReport(voting,classes,X_train,y_train,X_test,y_test)\n",
    "#     warnings.filterwarnings(\"default\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
