{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold, RandomizedSearchCV \n",
    "from sklearn.linear_model import Perceptron, LogisticRegressionCV, RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score,mean_absolute_error, confusion_matrix, silhouette_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc, classification_report,precision_score,recall_score,log_loss,f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, LabelEncoder, OneHotEncoder, MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer,minmax_scale\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import tree\n",
    "import pandas_bokeh\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy import mean, std\n",
    "import pandas.testing as tm\n",
    "from scipy import stats\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#other\n",
    "from math import sqrt\n",
    "import inspect\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from scipy.stats import loguniform, uniform\n",
    "from bokeh import io\n",
    "\n",
    "import eli5\n",
    "\n",
    "from yellowbrick.features import Rank2D\n",
    "from yellowbrick.features import PCA as PCA_YB\n",
    "from yellowbrick.features.radviz import RadViz\n",
    "from yellowbrick.features import pca_decomposition\n",
    "from yellowbrick.features import Manifold\n",
    "from yellowbrick.features import JointPlotVisualizer\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from yellowbrick.model_selection import CVScores\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.features import ParallelCoordinates\n",
    "from yellowbrick.model_selection import RFECV\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2n Cycle' 'Basic' 'Graduation' 'Master' 'PhD']\n",
      "0    1906\n",
      "1     334\n",
      "Name: Response, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://gist.githubusercontent.com/YHYeoh/ad1a7f7170c72d621d05a70637540152/raw/5a6059c199e2c46d2f3d258f03d93cfea98e2749/marketing_campaign.csv\"\n",
    "data = pd.read_csv(DATASET_URL, sep = ';')\n",
    "\n",
    "pd.set_option('plotting.backend','pandas_bokeh')\n",
    "\n",
    "data.fillna(method = \"ffill\", inplace = True)\n",
    "data.isnull().values.any()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "data[\"Education\"] = label_encoder.fit_transform(data[\"Education\"])\n",
    "print(label_encoder.classes_)\n",
    "# enc_df = pd.DataFrame(enc.fit_transform(data[[\"Marital_Status\"]]).toarray())\n",
    "# print(enc.get_feature_names())\n",
    "# data = data.join(enc_df)\n",
    "data_copy = data\n",
    "marital_status_ohe = pd.get_dummies(data[\"Marital_Status\"],prefix=\"Marital\")\n",
    "ohe_cols = marital_status_ohe.columns\n",
    "data = pd.concat([data, marital_status_ohe], axis=1)\n",
    "\n",
    "\n",
    "data['enroll_year'] = pd.DatetimeIndex(data.Dt_Customer).year\n",
    "data['enroll_month'] = pd.DatetimeIndex(data.Dt_Customer).month\n",
    "data['enroll_day'] = pd.DatetimeIndex(data.Dt_Customer).day\n",
    "\n",
    "data.drop([\"ID\", 'Dt_Customer',\"Z_CostContact\",\"Z_Revenue\",\"Marital_Status\"], axis=1, inplace=True)\n",
    "\n",
    "categorical = ['Marital_Status']\n",
    "numerical = ['Year_Birth', 'Education', 'Marital_Status', 'Income', 'Kidhome',\n",
    "       'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
    "       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n",
    "       'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3',\n",
    "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2',\n",
    "       'Complain', 'enroll_year', 'enroll_month', 'enroll_day']\n",
    "numerical_no_bool = ['Education','Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth','enroll_day','enroll_month','enroll_year']\n",
    "\n",
    "y = data.Response\n",
    "print(y.value_counts())\n",
    "X = data.drop(['Response'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.3)\n",
    "X_train_cont = X_train.drop(['AcceptedCmp3',\n",
    "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Education','Complain','Year_Birth','Marital_Absurd', 'Marital_Alone', 'Marital_Divorced',\n",
    "       'Marital_Married', 'Marital_Single', 'Marital_Together',\n",
    "       'Marital_Widow', 'Marital_YOLO', 'enroll_year', 'enroll_month',\n",
    "       'enroll_day'],axis=1)\n",
    "X_test_cont = X_test.drop(['AcceptedCmp3',\n",
    "       'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2','Education','Complain','Year_Birth','Marital_Absurd', 'Marital_Alone', 'Marital_Divorced',\n",
    "       'Marital_Married', 'Marital_Single', 'Marital_Together',\n",
    "       'Marital_Widow', 'Marital_YOLO', 'enroll_year', 'enroll_month',\n",
    "       'enroll_day'],axis=1)\n",
    "X_cont_column = X_train_cont.columns\n",
    "pcaX_train = X_train_cont\n",
    "pcaX_test = X_test_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasmethod(obj, name):\n",
    "\treturn inspect.ismethod(getattr(obj, name, None))\n",
    "\n",
    "def ROC_Curve_Plot(model,X_test,y_test,name):\n",
    "\tpredProb = model.predict_proba(X_test)\n",
    "\tpreds = predProb[:,1]\n",
    "\tfpr, tpr, threshold = roc_curve(y_test, preds,pos_label=1)\n",
    "\troc_auc = auc(fpr, tpr)\n",
    "\tplt.close()\n",
    "\tplt.title(name+' Receiver Operating Characteristic')\n",
    "\tplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "\tplt.legend(loc = 'lower right')\n",
    "\tplt.plot([0, 1], [0, 1],'r--')\n",
    "\tplt.ylabel('True Positive Rate')\n",
    "\tplt.xlabel('False Positive Rate')\n",
    "\tplt.show()\n",
    "\treturn fpr,tpr\n",
    "\n",
    "def setupPreprocessPipeline(scaler):\n",
    "\tss = Pipeline(steps=[('scaler',scaler)])\n",
    "\t#ohe = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "\tpreprocess = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('cont', ss, numerical_no_bool)\n",
    "                        #('cat', ohe, categorical),\n",
    "                        #('le', le, ordinal),\n",
    "                        ],remainder='passthrough')\n",
    "\treturn preprocess\n",
    "\n",
    "def feature_importance(classifier, feature_names, scaler_name):\n",
    "\tif (hasattr(classifier,'coef_')):\n",
    "\t\timportance = classifier.coef_[0]\n",
    "\telif (hasattr(classifier,'coefs_')):\n",
    "\t\timportance = classifier.coefs_\n",
    "\telif (hasattr(classifier,'feature_importances_')):\n",
    "\t\timportance = classifier.feature_importances_\n",
    "\telse:\n",
    "\t\tprint(\"Cannot extract feature importance, skipping\")\n",
    "\t\treturn\n",
    "\n",
    "\t#for i,v in enumerate(importance):\n",
    "\t#\tprint('Feature: %d, Score: %.5f' % (i,v))\n",
    "\tzipped = zip(feature_names, importance)\n",
    "\tdf = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n",
    "\t# Sort the features by the absolute value of their coefficient\n",
    "\tdf[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n",
    "\tdf[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n",
    "\tdf = df.sort_values(\"abs_value\", ascending=False)\n",
    "\t# plot feature importance\n",
    "\tfig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\tsns.barplot(x=\"feature\",\n",
    "\t            y=\"value\",\n",
    "\t            data=df.head(20),\n",
    "\t           palette=df.head(20)[\"colors\"])\n",
    "\tplt.gcf().subplots_adjust(bottom=0.30)\n",
    "\tax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=14)\n",
    "\tax.set_title(\"Top 20 Features for {} w/ {}\".format(classifier.__class__.__name__, scaler_name), fontsize=25)\n",
    "\tax.set_ylabel(\"Coef\", fontsize=22)\n",
    "\tax.set_xlabel(\"Feature Name\", fontsize=22)\n",
    "\tplt.show()\n",
    "\n",
    "def evaluation(y, y_hat, title):\n",
    "\tcm = confusion_matrix(y, y_hat)\n",
    "\tprecision = precision_score(y, y_hat)\n",
    "\trecall = recall_score(y, y_hat)\n",
    "\taccuracy = accuracy_score(y,y_hat)\n",
    "\tf1 = f1_score(y,y_hat)\n",
    "\tprint('Recall: ', recall)\n",
    "\tprint('Accuracy: ', accuracy)\n",
    "\tprint('Precision: ', precision)\n",
    "\tprint('F1: ', f1)\n",
    "\tsns.heatmap(cm,  cmap= 'PuBu', annot=True, fmt='g', annot_kws=    {'size':20})\n",
    "\tplt.xlabel('predicted', fontsize=18)\n",
    "\tplt.ylabel('actual', fontsize=18)\n",
    "\tplt.title(title, fontsize=18)\n",
    "\tplt.show()\n",
    "    \n",
    "def metrics_summary(y_test,y_pred):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\taccuracy=accuracy_score(y_test, y_pred)\n",
    "\tprecision = precision_score(y_test, y_pred)\n",
    "\trecall =  recall_score(y_test, y_pred) #sensitivity\n",
    "\tspecificity = tn / (tn+fp)\n",
    "\tg_mean= sqrt(recall * specificity)\n",
    "\tmse =mean_squared_error(y_test, y_pred, squared=False)\n",
    "\tr2=r2_score(y_test, y_pred)\n",
    "\tros = roc_auc_score(y_test, y_pred)\n",
    "\tll = log_loss(y_test, y_pred)\n",
    "\tf1 = f1_score(y_test, y_pred)\n",
    "\t\n",
    "\tmetrics_collection_dict ={\n",
    "        'accuracy':['accuracy',accuracy],\n",
    "        'precision':['precision',precision],\n",
    "        'recall':['recall',recall],\n",
    "        'specificity':['specificity',specificity],\n",
    "        'g_mean':['g_mean',g_mean],\n",
    "        'mean_square_error':['mean_square_error',mse],\n",
    "        'r2':['r2',r2],\n",
    "        'roc_auc_score':['roc_auc_score',ros],\n",
    "        'log_loss':['log_loss',ll],\n",
    "        'f1_score':['f1_score',f1]\n",
    "    } \n",
    "\treturn metrics_collection_dict\n",
    "\n",
    "def correlationPlot():\n",
    "\tvisualizer = Rank2D(\n",
    "        features=X.columns, algorithm='covariance'\n",
    "    )\n",
    "\tvisualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "\tvisualizer.transform(X)             # Transform the data\n",
    "\tvisualizer.show()                   # Finalize and render the figure\n",
    "\n",
    "def radVisualize():\n",
    "\tvisualizer = RadViz() #nice\n",
    "\tvisualizer.fit(X, y)\n",
    "\tvisualizer.transform(X)\n",
    "\tvisualizer.show()\n",
    "def pca_scatter_plot():\n",
    "\tvisualizer = pca_decomposition(X, y, scale=True, classes=['yes','no'])\n",
    "\tvisualizer.show()\n",
    "def precision_recall_curve(model):\n",
    "\tviz = PrecisionRecallCurve(model)\n",
    "\tviz.fit(X_train, y_train)\n",
    "\tviz.score(X_test, y_test)          #ok\n",
    "\tviz.show()\n",
    "    \n",
    "def overallClassificationReport(model,classes):\n",
    "\tvisualizer = ClassificationReport(model, classes=classes, support=True) #might can change\n",
    "\tvisualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "\tvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "\tvisualizer.show()\n",
    "\n",
    "def class_predict_err_plot(model,classes):\n",
    "\tvisualizer = ClassPredictionError(model, classes=classes)\n",
    "\t# Fit the training data to the visualizer\n",
    "\tvisualizer.fit(X_train, y_train)\n",
    "\t# Evaluate the model on the test data\n",
    "\tvisualizer.score(X_test, y_test)\n",
    "\t# Draw visualization\n",
    "\tvisualizer.show()\n",
    "\n",
    "def learning_curve_plot(model):\n",
    "\tcv = StratifiedKFold(n_splits=12)\n",
    "\tsizes = np.linspace(0.3, 1.0, 10)\n",
    "\n",
    "\t# Instantiate the classification model and visualizer\n",
    "\tvisualizer = LearningCurve(\n",
    "\t    model, cv=cv, scoring='f1_weighted', train_sizes=sizes, n_jobs=4\n",
    "\t)\n",
    "\tvisualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "\tvisualizer.show()\n",
    "    \n",
    "def cv_scores_plot(model):\n",
    "\tcv = StratifiedKFold(n_splits=12, random_state=42, shuffle= True)\n",
    "\tvisualizer = CVScores(model, cv=cv, scoring='f1_weighted')\n",
    "\n",
    "\tvisualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "\tvisualizer.show()\n",
    "def overall_feature_importance(model):\n",
    "\tlabels = list(map(lambda s: s.title(), X.columns))\n",
    "\tviz = FeatureImportances(model, labels=labels, relative=False, topn = 8)\n",
    "\tviz.fit(X, y)\n",
    "\tviz.show()\n",
    "def RFECV_plot(model):\n",
    "\tcv= StratifiedKFold(5)\n",
    "\t# Instantiate RFECV visualizer with a linear SVM classifier\n",
    "\tvisualizer = RFECV(model, cv= cv)\n",
    "\tvisualizer.fit(X, y)        # Fit the data to the visualizer\n",
    "\tvisualizer.show()      #ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaParamGrid = [{\n",
    "    'transformer':PCA(),'param_grid':{'n_components':list(range(2,8)),'random_state':[42]\n",
    "                                      ,'whiten':[True,False]\n",
    "                                      ,'svd_solver':['full', 'arpack', 'randomized']}\n",
    "},{\n",
    "    'transformer':KernelPCA(),\n",
    "    'param_grid':{'gamma':loguniform(1e-6, 100),'n_components':list(range(2,8))\n",
    "                  ,'random_state':[42],'kernel':['rbf'],\n",
    "                  'alpha':loguniform(1e-6, 100),'eigen_solver':['dense', 'arpack']\n",
    "                  ,'n_jobs':[-1],'max_iter':list(range(1,1000)),'fit_inverse_transform':[True,False]}\n",
    "},\n",
    "    {\n",
    "        'transformer':KernelPCA(),\n",
    "    'param_grid':{'gamma':loguniform(1e-6, 100),'n_components':list(range(2,8))\n",
    "                  ,'random_state':[42],'kernel':['poly'],\n",
    "                  'alpha':loguniform(1e-6, 100),'degree':list(range(3,8))\n",
    "                  ,'n_jobs':[-1],'max_iter':list(range(1,1000)),'eigen_solver':['dense', 'arpack'],\n",
    "                 'fit_inverse_transform':[True,False]}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def scorer(pcamodel, X, y=None):\n",
    "    try:\n",
    "        X_val = X.values\n",
    "    except:\n",
    "        X_val = X\n",
    "    \n",
    "    try:\n",
    "        y_val = y.values\n",
    "    except:\n",
    "        y_val = y\n",
    "    data_inv = pcamodel.fit(X_val,y_val).transform(X_val)\n",
    "    reconstructed = pcamodel.inverse_transform(data_inv)\n",
    "    #find reconstrucition error\n",
    "    mse = mean_squared_error(reconstructed.ravel(), X_val.ravel())\n",
    "    return abs(mse)\n",
    "\n",
    "def pcaComparison(X_train,y_train,X_test,y_test):\n",
    "    cv=10\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train,y_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    pcaPerformance = pd.DataFrame()\n",
    "    for transformer in pcaParamGrid :\n",
    "        pca = transformer['transformer']\n",
    "        param_grid =  transformer['param_grid']\n",
    "        PCASearch = RandomizedSearchCV(pca,param_grid,n_iter=10,verbose=2,\n",
    "                         scoring= scorer,\n",
    "                         n_jobs=-1,cv=cv,random_state=42)\n",
    "        PCASearch = PCASearch.fit(X_train_scaled,y_train)\n",
    "\n",
    "        param = PCASearch.best_params_\n",
    "        name = PCASearch.best_estimator_.__class__.__name__\n",
    "        score = PCASearch.best_score_\n",
    "        pcaResult = {\"Model\":name,\"MSE\": score,\"Parameter\":param}\n",
    "        pcaPerformance = pcaPerformance.append(pcaResult,ignore_index=True)\n",
    "    pcaPerformance.sort_values(by='MSE',ascending=True,inplace=True)\n",
    "    return pcaPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "pcaResult = pcaComparison(pcaX_train,y_train,pcaX_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 KernelPCA\n",
      "3.5866445054136334e-31\n",
      "{'alpha': 7.577453045410569, 'degree': 7, 'eigen_solver': 'dense', 'fit_inverse_transform': True, 'gamma': 1.2767906371238508e-06, 'kernel': 'poly', 'max_iter': 601, 'n_components': 5, 'n_jobs': -1, 'random_state': 42}\n",
      "\n",
      "\n",
      "2 KernelPCA\n",
      "2.5475797815164096e-18\n",
      "{'alpha': 2.3528990899815337e-06, 'eigen_solver': 'dense', 'fit_inverse_transform': True, 'gamma': 2.3130924416844095e-05, 'kernel': 'rbf', 'max_iter': 167, 'n_components': 3, 'n_jobs': -1, 'random_state': 42}\n",
      "\n",
      "\n",
      "3 PCA\n",
      "0.3641436844031753\n",
      "{'whiten': True, 'svd_solver': 'arpack', 'random_state': 42, 'n_components': 3}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for rowNo,result in pcaResult.iterrows():\n",
    "    mse,model,param = result\n",
    "    print(str(i)+\" \"+str(model))\n",
    "    print(mse)\n",
    "    print(param)\n",
    "    print(\"\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KernelPCA has the lowest error\n",
    "kpca = KernelPCA(alpha= 7.577453045410569, degree= 7, eigen_solver= \"dense\"\n",
    "                 , fit_inverse_transform= True, gamma= 1.2767906371238508e-06\n",
    "                 , kernel= \"poly\", max_iter= 601, n_components= 5, n_jobs= -1, random_state= 42)\n",
    "scaler= StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(pcaX_train,y_train)\n",
    "X_test_scaled = scaler.transform(pcaX_test)\n",
    "\n",
    "kpca = kpca.fit(X_train_scaled,y_train)\n",
    "transformedXTrain = kpca.transform(X_train_scaled)\n",
    "transformedXTest=kpca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpcaCol = [\"PCA1\",\"PCA2\",\"PCA3\",\"PCA4\",\"PCA5\"]\n",
    "kpcaTrain = pd.DataFrame(transformedXTrain,columns = kpcaCol)\n",
    "kpcaTest = pd.DataFrame(transformedXTest, columns = kpcaCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance : [5.38199521e-05 1.58401800e-05 9.23942910e-06 8.94696808e-06\n",
      " 7.43816975e-06]\n",
      "Explained Variance Ratio: [0.5648331  0.16624054 0.09696656 0.09389722 0.07806258]\n"
     ]
    }
   ],
   "source": [
    "explained_variance = np.var(transformedXTrain, axis=0)\n",
    "explained_variance_ratio = explained_variance / np.sum(explained_variance)\n",
    "print(\"Explained Variance : \" +str(explained_variance))\n",
    "print(\"Explained Variance Ratio: \"+str(explained_variance_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000160</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>-0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>-0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005094</td>\n",
       "      <td>-0.003583</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.005191</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>-0.003859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>-0.001499</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>-0.002863</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>-0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>-0.003009</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>-0.001485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PCA1      PCA2      PCA3      PCA4      PCA5\n",
       "0   -0.000160  0.008310  0.000826 -0.002955 -0.000923\n",
       "1   -0.000025  0.006932  0.002545 -0.001326 -0.000602\n",
       "2   -0.005094 -0.003583 -0.000943  0.001085 -0.002980\n",
       "3    0.018443 -0.005191 -0.001657 -0.006741  0.000458\n",
       "4    0.006501  0.008878  0.002508  0.003399 -0.003859\n",
       "..        ...       ...       ...       ...       ...\n",
       "667  0.007894  0.007176  0.000626 -0.001499  0.000149\n",
       "668  0.007123  0.004609  0.002419  0.001028  0.003577\n",
       "669 -0.002863 -0.000980 -0.000024  0.002811 -0.001831\n",
       "670  0.003611  0.004845 -0.000145  0.002129  0.003467\n",
       "671 -0.003009  0.001403  0.005669 -0.002017 -0.001485\n",
       "\n",
       "[672 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpcaTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76100013, -0.85240427, -0.91446557,  1.34095667,  0.97875804,\n",
       "        0.0482593 ,  1.3826008 , -0.13276687, -0.31339209,  0.23772792,\n",
       "       -0.66741304,  0.72081595,  1.42453623,  0.70457026, -0.9429703 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\tSGDClassifier(max_iter = 1000,penalty = \"elasticnet\"),#tol=1e-3),\n",
    "\tLinearSVC(max_iter=2000), \n",
    "\tGaussianProcessClassifier(),\n",
    "\tExtraTreeClassifier(),\n",
    "\tBernoulliNB(),\n",
    "\tLogisticRegressionCV(max_iter= 1200), \n",
    "\tRidgeClassifierCV(),\n",
    "\tSVC(kernel = 'linear',max_iter= -1), \n",
    "\tPerceptron(),\n",
    "\tPassiveAggressiveClassifier(), \n",
    "\tDecisionTreeClassifier(), #no coef \n",
    "\tKNeighborsClassifier(),#no feat_import, use permutation_importance \n",
    "\tGaussianNB(), #no feat_import, use permutation_importance \n",
    "\tLGBMClassifier(),#no coef \n",
    "\tRandomForestClassifier(), #no coef \n",
    "\tGradientBoostingClassifier(),#no coef \n",
    "\tPassiveAggressiveClassifier(), \n",
    "\tExtraTreesClassifier(), #no coef \n",
    "\tXGBClassifier(),\n",
    "\tAdaBoostClassifier(), #no coef \n",
    "\t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below column is previous pca attemps, examined by models instead of restructuring mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "def scorer(pcamodel, X, y=None):\n",
    "\n",
    "    try:\n",
    "        X_val = X.values\n",
    "    except:\n",
    "        X_val = X\n",
    "        \n",
    "    # Calculate and inverse transform the data\n",
    "    data_inv = pcamodel.fit(X_val,y).transform(X_val)\n",
    "    data_inv = pcamodel.inverse_transform(data_inv)\n",
    "    \n",
    "    # The error calculation\n",
    "    mse = mean_squared_error(data_inv.ravel(), X_val.ravel())\n",
    "    \n",
    "    # Larger values are better for scorers, so take negative value\n",
    "    return -1.0 * mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcaParamGrid = {{\n",
    "    'transformer':KernelPCA(),\n",
    "    'param_grid':{'gamma':[0.0001,0.001, 0.01, 0.05, 0.1, 0.5, 1.0,1.5,2],'n_components':[2, 3, 4,5,6,7,8],'random_state':[42]}\n",
    "},{\n",
    "    'transformer':PCA(),'param_grid':{'n_components':[2, 3, 4,5,6,7,8],'random_state':[42]}\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
